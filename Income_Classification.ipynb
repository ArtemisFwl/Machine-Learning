{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db642d6a",
   "metadata": {},
   "source": [
    "# Income Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957ac9c4",
   "metadata": {},
   "source": [
    "Use the dataset and train a classification model to predict if the income of a person is lesss than 50K or greater then 50K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37cf1a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the Libraries \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f9ccea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7113a379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income_&gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>Private</td>\n",
       "      <td>366425</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>16</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>99999</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>Private</td>\n",
       "      <td>244602</td>\n",
       "      <td>12th</td>\n",
       "      <td>8</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>174201</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>110199</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>149248</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational-num      marital-status  \\\n",
       "0   67    Private  366425     Doctorate               16            Divorced   \n",
       "1   17    Private  244602          12th                8       Never-married   \n",
       "2   31    Private  174201     Bachelors               13  Married-civ-spouse   \n",
       "3   58  State-gov  110199       7th-8th                4  Married-civ-spouse   \n",
       "4   25  State-gov  149248  Some-college               10       Never-married   \n",
       "\n",
       "         occupation   relationship   race gender  capital-gain  capital-loss  \\\n",
       "0   Exec-managerial  Not-in-family  White   Male         99999             0   \n",
       "1     Other-service      Own-child  White   Male             0             0   \n",
       "2   Exec-managerial        Husband  White   Male             0             0   \n",
       "3  Transport-moving        Husband  White   Male             0             0   \n",
       "4     Other-service  Not-in-family  Black   Male             0             0   \n",
       "\n",
       "   hours-per-week native-country  income_>50K  \n",
       "0              60  United-States            1  \n",
       "1              15  United-States            0  \n",
       "2              40  United-States            1  \n",
       "3              40  United-States            0  \n",
       "4              40  United-States            0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78cb9b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43957, 15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5727f7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are 43957 instances and 15 features out of which one is target feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa51e5c",
   "metadata": {},
   "source": [
    "# 2) Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19022eb1",
   "metadata": {},
   "source": [
    "Feature engineering steps: \n",
    "    \n",
    "    1) Missing values \n",
    "    \n",
    "    2) Outliers \n",
    "    \n",
    "    3) Dummy Variables \n",
    "    \n",
    "    4) Correlation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ff7fd5",
   "metadata": {},
   "source": [
    "### 1) Checking for the missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e98f392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                   0\n",
       "workclass          2498\n",
       "fnlwgt                0\n",
       "education             0\n",
       "educational-num       0\n",
       "marital-status        0\n",
       "occupation         2506\n",
       "relationship          0\n",
       "race                  0\n",
       "gender                0\n",
       "capital-gain          0\n",
       "capital-loss          0\n",
       "hours-per-week        0\n",
       "native-country      763\n",
       "income_>50K           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14f4a348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#three features have missing values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d0d20c",
   "metadata": {},
   "source": [
    "Fill the missing values with mode in categorical features and with mean in numerical features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f23e17b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['workclass'].fillna(df['workclass'].mode, inplace=True)\n",
    "df['occupation'].fillna(df['occupation'].mode, inplace=True)\n",
    "df['native-country'].fillna(df['native-country'].mode, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dca48b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                0\n",
       "workclass          0\n",
       "fnlwgt             0\n",
       "education          0\n",
       "educational-num    0\n",
       "marital-status     0\n",
       "occupation         0\n",
       "relationship       0\n",
       "race               0\n",
       "gender             0\n",
       "capital-gain       0\n",
       "capital-loss       0\n",
       "hours-per-week     0\n",
       "native-country     0\n",
       "income_>50K        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46f76a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the null values are replaced with mode values of the respective column "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84de175",
   "metadata": {},
   "source": [
    "### 2) Dropping the redundant features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df757cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income_&gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>Private</td>\n",
       "      <td>366425</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>16</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>99999</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>Private</td>\n",
       "      <td>244602</td>\n",
       "      <td>12th</td>\n",
       "      <td>8</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  fnlwgt  education  educational-num marital-status  \\\n",
       "0   67   Private  366425  Doctorate               16       Divorced   \n",
       "1   17   Private  244602       12th                8  Never-married   \n",
       "\n",
       "        occupation   relationship   race gender  capital-gain  capital-loss  \\\n",
       "0  Exec-managerial  Not-in-family  White   Male         99999             0   \n",
       "1    Other-service      Own-child  White   Male             0             0   \n",
       "\n",
       "   hours-per-week native-country  income_>50K  \n",
       "0              60  United-States            1  \n",
       "1              15  United-States            0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2158da",
   "metadata": {},
   "source": [
    "Here by observation we can see that education and educational-num give the same information. Hence we can drop one of the feature. We prefer to keep the numerial features so we will drop the education column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bec44e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('native-country', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eda0957f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43957, 14)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c7ac4c",
   "metadata": {},
   "source": [
    "### 3) Checking for outliers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e154ff1",
   "metadata": {},
   "source": [
    "To check for outliers we can make the boxplot. It will give us an idea. For simplicity in this program we will deal with outliers in age column only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb778fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='age'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data=df, x='age')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f859d74",
   "metadata": {},
   "source": [
    "### Write a function to find the outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20622d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_outliers (df):\n",
    "    q1=df.quantile(0.25)\n",
    "    q3=df.quantile(0.75)\n",
    "    \n",
    "    iqr= (q3-q1)\n",
    "    \n",
    "    lower = q1-1.5*iqr\n",
    "    upper= q3+1.5*iqr\n",
    "    \n",
    "    outliers=[]\n",
    "    \n",
    "    for i in df:\n",
    "        if i<lower or i>upper:\n",
    "            outliers.append(i)\n",
    "            \n",
    "            \n",
    "    return outliers \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a8a25c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "olr=ret_outliers(df['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ebe8020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(olr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0384288d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(olr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e22ec65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(olr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dd279f",
   "metadata": {},
   "source": [
    "We see that the feature age has 193 outliers with max value of 90 anf min value of 79"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56340ca",
   "metadata": {},
   "source": [
    "For working class people generally the age is between 18 to 65"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f65192",
   "metadata": {},
   "source": [
    "In this program we will remove the upper limit outliers i.e age >79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c352aba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['age']>79].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2749f13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43791, 14)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39131f91",
   "metadata": {},
   "source": [
    "### 4) Checking for Correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c2df2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income_&gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.074975</td>\n",
       "      <td>0.039525</td>\n",
       "      <td>0.076638</td>\n",
       "      <td>0.056582</td>\n",
       "      <td>0.085505</td>\n",
       "      <td>0.239014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fnlwgt</th>\n",
       "      <td>-0.074975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.041381</td>\n",
       "      <td>-0.003273</td>\n",
       "      <td>-0.005875</td>\n",
       "      <td>-0.013147</td>\n",
       "      <td>-0.006995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educational-num</th>\n",
       "      <td>0.039525</td>\n",
       "      <td>-0.041381</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.126554</td>\n",
       "      <td>0.081100</td>\n",
       "      <td>0.144100</td>\n",
       "      <td>0.334028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-gain</th>\n",
       "      <td>0.076638</td>\n",
       "      <td>-0.003273</td>\n",
       "      <td>0.126554</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.031451</td>\n",
       "      <td>0.082449</td>\n",
       "      <td>0.222809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-loss</th>\n",
       "      <td>0.056582</td>\n",
       "      <td>-0.005875</td>\n",
       "      <td>0.081100</td>\n",
       "      <td>-0.031451</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.055521</td>\n",
       "      <td>0.145384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours-per-week</th>\n",
       "      <td>0.085505</td>\n",
       "      <td>-0.013147</td>\n",
       "      <td>0.144100</td>\n",
       "      <td>0.082449</td>\n",
       "      <td>0.055521</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.227622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income_&gt;50K</th>\n",
       "      <td>0.239014</td>\n",
       "      <td>-0.006995</td>\n",
       "      <td>0.334028</td>\n",
       "      <td>0.222809</td>\n",
       "      <td>0.145384</td>\n",
       "      <td>0.227622</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      age    fnlwgt  educational-num  capital-gain  \\\n",
       "age              1.000000 -0.074975         0.039525      0.076638   \n",
       "fnlwgt          -0.074975  1.000000        -0.041381     -0.003273   \n",
       "educational-num  0.039525 -0.041381         1.000000      0.126554   \n",
       "capital-gain     0.076638 -0.003273         0.126554      1.000000   \n",
       "capital-loss     0.056582 -0.005875         0.081100     -0.031451   \n",
       "hours-per-week   0.085505 -0.013147         0.144100      0.082449   \n",
       "income_>50K      0.239014 -0.006995         0.334028      0.222809   \n",
       "\n",
       "                 capital-loss  hours-per-week  income_>50K  \n",
       "age                  0.056582        0.085505     0.239014  \n",
       "fnlwgt              -0.005875       -0.013147    -0.006995  \n",
       "educational-num      0.081100        0.144100     0.334028  \n",
       "capital-gain        -0.031451        0.082449     0.222809  \n",
       "capital-loss         1.000000        0.055521     0.145384  \n",
       "hours-per-week       0.055521        1.000000     0.227622  \n",
       "income_>50K          0.145384        0.227622     1.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbf1bfb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAKNCAYAAACtASYjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAACRyUlEQVR4nOzdd3gU5drH8e+dhF5TSAAB6UVEQSmK1NAUUCxgb0eUo+/BhuLBg0gTsB5FEQUrIB49gjRBEWmhNykKqAcVBIQUeodsnvePXUMaEDTZTbK/z3Xtxc7MPbP3szO7++R+ZgZzziEiIiIi+V9IoBMQERERkZyhjp2IiIhIAaGOnYiIiEgBoY6diIiISAGhjp2IiIhIAaGOnYiIiEgBoY6diIiIiJ+Z2ftmlmBm359huZnZ62a2xcw2mNll2dmuOnYiIiIi/vchcPVZll8D1PI9egFvZWej6tiJiIiI+JlzLg7Ye5aQbsB457UcKGtmFc61XXXsRERERPKeC4DtaaZ3+OadVViupSPnbVDdQkH7/7sN+nZXoFMIKHcouNvPqaOBziBwQosEOoPASj4W6AwCym1fGegUAiqk+aPmz9fz5+/s4B+T/453CPUPY51zY89jE1m9N+fMXx07ERERkRzm68SdT0cuox1A5TTTlYDfz7WShmJFREQkKJgfHzlgOnC37+rYK4ADzrlzDu+oYiciIiLiZ2b2H6ANEGVmO4CBQCEA59zbwCygM7AFOAr8LTvbVcdOREREgoL59Yy+s3PO3XaO5Q74x/luV0OxIiIiIgWEKnYiIiISFIKhmhUMbRQREREJCurYiYiIiBQQGooVERGRoJCXLp7ILarYiYiIiBQQqtiJiIhIUAiCgp0qdiIiIiIFhSp2IiIiEhR0jp2IiIiI5Buq2ImIiEhQCIZqVjC0UURERCQoqGInIiIiQUHn2ImIiIhIvqGKnYiIiASFICjYqWInIiIiUlCoYiciIiJBQefYiYiIiEi+oYqdiIiIBIUgKNipYiciIiJSUKhjJyIiIlJAaChWREREgkJIEIzFqmInIiIiUkCoYiciIiJBIQgKdqrYiYiIiBQUqtiJiIhIUNANikVEREQk31DFTkRERIJCEBTsVLETERERKShUsRO6DXuH2m06c2RPAqOvaxTodHKEc45hL77GwiXLKFq0KM8P7k/9enUyxW3f+Tt9+g3kwIGDXFSvNi8+9yyFCxXi3XETmTHrawA8Hg8//7qNZfNmUrZMaWI730SJEsUJCQkhNDSUzz9+39/NOy+LVqxl2OsfkJKSQvcu7eh15w3pljvnGPb6+8QtX0vRIoUZ8XRv6tepnrrc4/HQvdc/iY6KYMwL//J3+udt0coNDHvzI297O7em123XplvunGPYmx8Rt2I9RYsUYcRTD1C/dlV+2b6LPkPfTI3bviuBR+69kXtuuprHh47i1+27ATh4+CilSxZn6tjn/Nqu7Fq0Yh3DRn1IiieF7l1i6XXH9emWO+cY9saH3v1dtAgj+j1E/dre/R17S29KFC9KqO/Ynjx2BACPD36NX3/7HUjT/vde9Gu7smvRyg0MG/2xd/9f04pet3VNt9y7/ycSt3KD93h/6n7q16oKwIeTZjPpy4WYGbWqVWJE354UKVwYgAlT5jBx2lzCQkNo3exS+va6xd9NO2+LvvuN4R8v9r4XrS7igS6XpVs+Y9lPvDvrWwCKFynEwLtbU7dKVOpyT0oKPQZPIjq8BG8/1sWvueeWEHOBTiHXqWMnrJsyjpUTR3PD83m7g3I+4hYvY+tvO/h62qes/24jg4a/zGcT3skU9/LIt7j3jlvocnV7nn3uRSZN+YLbb76B+++5g/vvuQOAeQsX8+HETylbpnTqeuPGvkFEeFl/NedP83g8DHn1Xd7/97PElIugR69+xLZoTM2qlVNj4pavZduOXcz++A3Wb/ofg/89lv+OeT51+fhJs6h+YSUOHzkaiCacF48nhSGvj+f9F5/ytvf/BhJ75WXUrHpBakzcyg1s2xHP7PEvsX7zzwwe+SH/fXMQ1StXSO2seTwptL7lUdq3aAzAqwN6p67//FsfU6pEcf82LJs8nhSGjHyf91/uT0y5SHo8+DSxVzWmZtVKqTFxK9axbcduZk8c6d3fr77Hf98alrp8/KvPEl62dLrtvjrwsdTnz48en7fb/8YE3n+hr3f//2Mwsc0bUfPCDPt/Zzyzx73g2//j+e+oZ4lP2seEqXOY+d5wihYpzGND3mTm/BXc2Kkly9dtZt7StUwfO5TChQuxZ9/BALYyezwpKQydEMd7T15LTERJbh4yibYNq1LzgojUmEpRpRjf73rKlChK3IZtDBy3gE8HdE9dPmHOBqpXCOfw8ZOBaIL8SRqKFbatXsyxA3sDnUaOmrtwMdd3vRozo+ElF3Pw0CESEpPSxTjnWL5qDZ3atwHghms7M3dBXKZtzfzqG7pe3cEfaee4DZu3UOWC8lSuGEPhQoXo3O4q5i5elS5m7uJVdOvUxvte1a/NwcNHSUjaB8DuhD0sXLaGHl3aBSL987bhh5+pckE0lStGU7hQGJ3bXsHcpd+mi5m75Fu6dbzK296Lanrbu2d/uphlazdSuWI0F8REpZvvnOOrhSvpEntFbjflT9nwwxaqXBDj299hdI5tztwlGfb3klV069Qqzf4+QsKefdnavnOOr+Yvp0u7q3Ij/b9sw4+/UKVizOn936YZc5esTRczd+launXIev97PCkcP3GSZI+HYydOEh0ZDsAn0+fxwK1dKFy4EACR4ek7vnnRhl8SqBJdhsrRZSgcFkrnpjWZt/bXdDGNalWgTImiAFxaI4bde4+kLtu99zAL12+je6t6fs07t5kfH4Gijt15MLOpZrbGzDaaWS/fvJ5m9pOZLTCzd8xslG9+OTObbGarfI+8+U1YQMUnJFK+fHTqdPmYaOITEtPF7Nt/gNKlShIWFuaLKZcp5tix4yxaupyO7dqcnmlGz/97nBtvv49PJ0/LtTbkhPikvVSIPt05KV8ukvjEvRli9lAhOjJNTATxSXsAGP7GBzz50F1YPvl/eOKT9lGhXMa27MsQs5cK5SIyxKR/T2bNX55l5231dz8SGV6aqpXK53DmOSM+cW+G9kcSn5ih/YkZ36PTx4QZ9Ow7jBt79ePTGd9k2v7qDZuJDC9D1UoVcqkFf0180j4qRKfdt+HE78m4//dl2P/hxCftIyYqnPt6XE3s7U/Q8ubHKFWiGC0aXwzA1p27Wf39T9zcewh39hnBdz/84p8G/QUJ+45QPqJk6nRMREni9x05Y/zkuM20bFAldXrEfxbz5M1XEpJPPvtymjp25+c+59zlQGPgETO7ABgAXAF0AOqmiR0JvOqcawLcBLyb1QbNrJeZrTaz1Wv2p+Ru9kHEucznUVjGGxhlI2Z+3GIua3hJumHY/3zwFlP+8wHvjHqFiZ9+zqo163Ik51yRrfch82pmxvylq4kML8PFdWrkUnL+kZ37VqV9T06eSmbe0rVc3apppriZ85bTpe2VOZleDstqf2cnxhv08aghfP7OC7zzwtN8PHU2q9ZvShc3c+5SurRrnlPJ5rysjvfsxJhx4NAR5i5dyzcfvUTcp69y7PgJpn+zFPBW8g4eOsKnbwzgqV638Nhzo7P8jslL3Fn2c0YrNu9k8qLNPHGz99iev24rEaWKUb9qdJbx+ZkqdpLRI2a2HlgOVAbuAhY65/Y6504Bn6WJbQ+MMrN1wHSgtJmVyrhB59xY51xj51zjy8tqd/wVEz+dTLdb7qHbLfcQXS6K3bsTUpftjk8gulz6YbXw8LIcPHSY5ORkX0xippiZs+fS5er26ebFRJcDIDIinA6xrdiwMf2PX14SUy6SXQmnh6B3J+4hOio8i5g9aWL2Eh0Zwbff/ci8JauIvfkhnhj8Giu+/Z6+Q0f6Lfc/IyYqnF2JGduSob1REexKU7XMGLNo5XouqlWVqIgy6dZL9niYs2g1nds2y6Xs/7qYcpEZ2p/V/o44Y0xMlLeSFRlehvYtmrJh88+pccnJHuYsWknntnm3YxdTLoJdCWn37b7M+79cxv2/j+jIsiz7diOVykcRUbY0hcLC6NCiMWs3bvGuExVOhxaXY2ZcUrc6IWbsO3DIP436k2LCS7J77+HU6fi9h4kum/ncyB+3JzHgg/mMeqQz4SW9w7Jr/7eL+eu20u7JCTzx1tes2LyTp8bM8Vvu8teoJ5FNZtYGb2ftSufcpcBa4MezrBLii23oe1zgnMvb3wT53B233MS0T8cx7dNxtG/biqlffIVzjnUbvqdUyZKZOm1mRrPGlzH7mwUATJkxi9g2LVOXHzp0mFVr1tIuzbyjx45x+MiR1OdLlq2kVo3q5FUN6tZk245d7Pg9npOnTjFr7hJir2qSLia2RWOmzV7gfa82/kSpEsWJjgrnib/fwcLJY5n337d4ZeBjNLvsYl4a8GiAWpI9DepWZ9vOeHbsSuTkqWRmzV9ObPP0V3rHNm/EtK+XeNu7aYu3vZFlU5fPnJf1MOyyNRupVqUC5dMM4+U1DerUYNuO3ezYleBt/7ylxDZvnC4mtnljps2OS7+/I8M5euw4h48eA+DoseMsWb2B2tVOX2SzbM13VKtSkfJphu3zmgZ1qqXf/wtWZN7/VzZk2py0+78Y0ZFlqRAdyfrNP3Ps+Amccyxbu4nqVbxDzu2vuowV6zYD8OuO3ZxK9hBeJtPf6XlKg2rRbEs4wI7Eg5xM9jBr5RbaNqqWLub3PYd4ZNRXvPBAO6qVL5s6v0+PK1nw73uY+/JdvPJQR5rVu4AX/54/zzPOyMx/j0DRVbHZVwbY55w7amZ18Q6/vgO0NrNw4BDeIdfvfPFfA72BlwDMrKFzbp3fs86Gm16ZQNUmrSkeHkWfBb8y/40hrJ38QaDT+ktat7iShYuX0eG6mylWtCjDB52+TccDvZ/guWf7ERNdjr6PPsTj/Qby2uix1KtTmx7Xn741wpz5C7nqiqYUL1Ysdd6ePXv5Rx/vtjyeZLpe05FWV+XNE+kBwsJCGfDY/fR88jlSUlK4qXMstapV5pNpswG4tVsnWl9xGXHLvqXjbb0pWqQIw5/+vwBn/eeFhYYy4OG76fnPF0lJcdx0TStqVa3EJzPmAXDrtbG0bnYpcSvW0/GuvhQtWpjhfe9PXf/Y8RMsWfM9gx//W6Ztz5y/nK6xeXkY1re/H72Pnn2He/f3NW18+9tbbbm1WwdaX9GIuBVr6XjHoxQtUpjh/3wIgD37DtB7wMuAd+ixa7uraNmsYeq2Z85bStfYvH2qsHf/30nPfi972391S2pVvSDz/l+5gY53P+U93vv2BODSejXo2KoJNz40kLDQUOrVrMItXdoAcOPVrej/8ntce39/CoWF8fxT959xWDOvCAsN4Zk7WnL/KzNISXHc2LIutS6I4JP53wNwa9uLGT1tNfsPn2DIBO9FY6GhIUwa2COQaUsOsLx+nkBeYWZFgKnABXgrdeWAQUBt4Engd2AzsNc519/MooA3gXp4O9BxzrkHz/Yag+oWCtqdMejbXYFOIaDcoeBuP6fy/q1Uck1okUBnEFjJxwKdQUC57SsDnUJAhTR/1K895Lcahfntd/ahtckB6f2rYpdNzrkTwDUZ55vZaufcWDMLA6bgrdThnEsC8v4dLEVERIJE3q6z5gydY/fXDfJdIPE98Cveqp6IiIiI36li9xc5554MdA4iIiJybsFwWz5V7EREREQKCFXsREREJCgEQcFOFTsRERGRgkIVOxEREQkKefz2gzlCFTsRERGRAkIVOxEREQkKQVCwU8VOREREpKBQxU5ERESCgu5jJyIiIiL5hip2IiIiEhSCoGCnip2IiIhIQaGKnYiIiAQF3cdORERERPINdexERERECggNxYqIiEhQCIKRWFXsRERERAoKVexEREQkKOjiCRERERHJN1SxExERkaAQDNWsYGijiIiISFBQxU5ERESCgs6xExEREZF8QxU7ERERCQpBULBTxU5ERESkoFDFTkRERIJCSBCU7FSxExERESkgVLETERGRoBAEBTtV7EREREQKClXsREREJCjoHDsRERERyTfUsRMREREpIDQUm4cM+nZXoFMImEGXVQh0CgE1aOXWQKcQUK5Q8UCnIAFiRcsEOoXAqts10BkElWCoZgVDG0VERESCgip2IiIiEhRMF0+IiIiISH6hip2IiIgEhWCoZgVDG0VERESCgip2IiIiEhR0jp2IiIiI5Buq2ImIiEhQCDEX6BRynSp2IiIiIgWEKnYiIiISFIKhmhUMbRQREREJCqrYiYiISFDQVbEiIiIikm+oYiciIiJBIRiqWcHQRhEREZGgoI6diIiISAGhoVgREREJCrp4QkRERETyDVXsREREJCgEQzUrGNooIiIikueY2dVm9qOZbTGzflksL2NmM8xsvZltNLO/nWubqtiJiIhIUAjJQ+fYmVko8CbQAdgBrDKz6c65TWnC/gFscs5da2blgB/NbKJz7uSZtquKnYiIiIj/NQW2OOd+8XXUPgG6ZYhxQCkzM6AksBdIPttGVbETERGRoJDHroq9ANieZnoH0CxDzChgOvA7UAq4xTmXcraNqmInIiIiksPMrJeZrU7z6JUxJIvVXIbpTsA6oCLQEBhlZqXP9rqq2ImIiEhQ8Gc1yzk3Fhh7lpAdQOU005XwVubS+hvwvHPOAVvM7FegLrDyTBtVxU5ERETE/1YBtcysmpkVBm7FO+ya1m9AOwAziwHqAL+cbaOq2ImIiEhQyEvn2Dnnks2sNzAbCAXed85tNLMHfcvfBoYCH5rZd3iHbv/pnEs623bVsRMREREJAOfcLGBWhnlvp3n+O9DxfLapjp2IiIgEhWA4/ywY2igiIiISFFSxExERkaCQl/7nidyiip2IiIhIAaGKnYiIiASFICjYqWInIiIiUlCoYldAOecY9uJrLFyyjKJFi/L84P7Ur1cnU9z2nb/Tp99ADhw4yEX1avPic89SuFAh3h03kRmzvgbA4/Hw86/bWDZvJmXLlCa2802UKFGckJAQQkND+fzj9/3dvBzTbdg71G7TmSN7Ehh9XaNAp5NjnHMMe2UUC5es8O7/gU9Rv27tTHHbd+6iT/+hHDh4iIvq1OLFIU9TuFCh1OUbNv7ALff15tXhA7i6XWsAnh7yIgsWLycyvCxffJo39r1zjmGvjiFu6SqKFi3CiAF9qF+nZqa4Hb/vps+A5zlw8DAX1anBCwOfpHChQmdc/8SJk9z50FOcPHUKj8dDx7YteOSBOwEYOWY8cxctJyQkhIjwMox4pg8x5SL93XQg99oPEHvDvZQoXozQ0FBCQ0OY/MHrAPzwv18Y+OIojh49xgUVYnh58FOULFHcr+3OinOOYf9+i4XLVlG0SBGeH/AE9evWyhS3/ffd9HlmhO/Yr8mLg/pSuFAhft66nX899wobf/yZxx+8h553dAfgxImT3PHQk5w86T0WOsW25JEH7vJ3884pt46FX7btoM+A51PX375zF488cBf33Hq9H1sn2RG0FTsze8TMNpvZxLPEHM6B17nXzCr+1e2cr7jFy9j62w6+nvYpQ595ikHDX84y7uWRb3HvHbfw9fRPKV2qFJOmfAHA/ffcwbRPxzHt03H0efhBmlzekLJlTv/3dOPGvsG0T8fl604dwLop4/joga6BTiPHxS1dwdbfdvL15xMY+q8+DHr+tSzjXh41lntv787Xn0+gdOlSTJp2+nZKHo+Hl0eNpcUVjdOtc2PXTrz7+vMZNxVQcctWs237TmZ/9i5D+j3C4BdHZRn38pvvc8+tNzD7s3cpXaokk2d8fdb1CxcuxIejRjBtwptMGT+KxctXs+77HwDoeWd3pn80mqnjR9HmqqaMfv9j/zQ2C7nV/j+Mf/N5po4fldqpA3hmxEieeOhvzJj4Fh1aN+e9jyblXgPPQ9yyVWzd/jtff/Y+Q59+lEFnfC/e497bbuDrSe9TunRJJk2fDUDZ0qXo3+chet5+U7r4woULMW7UC0z/6C2mThjNomWrWff95lxvz/nKrWOh+oWVmDp+lO84GEmxokVp3/pKv7Urp4SY/x4Ba2PgXjrg/g/o7Jy7I5df5168/3mvX81duJjru16NmdHwkos5eOgQCYnpb1btnGP5qjV0at8GgBuu7czcBXGZtjXzq2/oenUHf6Ttd9tWL+bYgb2BTiPHzV24lOu7dPDu/wYXcfDQYRKS9qSL8e7/tXSK9VbibujSkbkLl6Qun/DpFDq1bUVkeHi69ZpcdillSp/1/6D2u7lxy+l2TTtvey+uy8HDR0hISr9fnXMsX7OBTm1bAHB95/Z8E7fsrOubGSWKFwMgOTmZ5GRP6p3r01anjh07jgXwlva51f6z+XXbDpo0uhiA5k0b8fWCJWeN95e5ccu4vvMfbanHwcNnOPZXr6dT25YA3NC5PXPjlgIQGVGWSy6qQ1hYaLp1Mh8LyVgePGPLH8fCstXrqXxBeS6oEOOfRsl5CcqOnZm9DVQHppvZATN738wWmNkvZvZIFvGjzew63/MpZva+73lPM3vO93yAmf1gZnPM7D9m9qSZdQcaAxPNbJ2ZFfNXG+MTEilfPjp1unxMNPEJieli9u0/QOlSJQkLC/PFlMsUc+zYcRYtXU7Hdm1OzzSj5/89zo2338enk6flWhvkz4tPTKJ8TJr9H12O+IT0Hft9Bw769n9oppj4hES+WbCYW2+61n9J/wXxiUlUiCmXOl2+XBTxGf6Q2X/gIKVLlkjT3igSEvecc32Px8P1d/fmqs6307xpIy6tXzc17tW3x9Gm29188fWCgA7L5Wb7zYyejz7Djfc+wqdTv0yNqVW9KvMWLQfgq3mL2JVw1v/lyG/iE/dQPjpNW6LLEZ+YvmPnPfZLpD/2M8RkxePx0O2u/6P5NbfSvOllXHpx3XOu42+5eSz8YdachXTp0CaXWpC7zI+PQAnKjp1z7kHgd6At8CpQF+gENAUGmlmhDKvEAS19zy8ALvI9bwEsMrPGwE1AI+BGvJ05nHOTgNXAHc65hs65YxlzMbNeZrbazFaPfX98TrYx07xMFYVsxMyPW8xlDS9JNwz7nw/eYsp/PuCdUa8w8dPPWbVmXY7kLDnnr+7/Yf9+kycf7kVoaGimmPwiY3uzaG621g8NDWXq+FEsmDaeDZt+4qeft6bGPP7gPSyYNp6uHdvw0aQZfzXlHJVT7f94zMt8Pu4N3vn3ED6e/AWr1n4HwPD+jzFx8hfceO8jHDl6jEJheeOU7Zz67stKaGgo0yaMZuH0j9iw6cd0x0JellPHAsDJU6eYt3gFV7drkROpSS7IG5/EwJvpnDsBnDCzBCAG2JFm+SLgMTO7CNgEhJtZBeBK4BGgJzDtj46bmWX7G945NxYYC8DRpPP8uKU38dPJ/Pfz6QA0qF+P3bsTUpftjk8gulxUuvjw8LIcPHSY5ORkwsLC2B2fmClm5uy5dLm6fbp5Mb6/hiMjwukQ24oNGzfR5PKGfyV1yQET/zuV/06dCUCDi+qwOz7N/k9IJDrDif3hZcv49r+HsLDQdDHfb/6JPv2HAt7K7sKlKwgLDaV9m7zzZT5x0gw+850X1aBeLXbFn642705MIjoqY3tLc/DwkTTtTUptb0y5qHOuX7pUSZpe1oBFy9dQu0bVdMu6dmzDg08OSr2wwh/81f4/LgiJjChL+9ZXsmHTTzRp1IDqVSvz/shhAPz62w4WLlmVe409h4mTpvPfaV8B0KBebXanGXnYnZBIdFREunjvsX8k/bGfIeZsSpcqSbPLLmHR8tWZjoVA8OdnYdGy1VxUpwZREelP0cgvdIPi4HEizXMPGTq8zrmdQDhwNd7q3SLgZuCwc+4QeeTWOHfcclPqBQ/t27Zi6hdf4Zxj3YbvKVWyZKZOm5nRrPFlzP5mAQBTZswitk3L1OWHDh1m1Zq1tEsz7+ixYxw+ciT1+ZJlK6lVo3ruN07O6Y6br2fax+8w7eN3aN+mBVNnzvHu/+82UapkiUxf7t7935DZ8xYCMGXm18S2ugqAedM+Zt70/zBv+n/oFNuagf98NE916gDu6H5t6snc7VpdybQv53rb+/0PlCpRItMPtZnR7LJLmD1/MQBTZ31Du5ZXABDbslmW6+/dd4CDh7zXUB0/foJlq9ZR/cJKAGzdvjN12/MWr6Cab76/+KP9R48d5/CRowAcPXacJSvWUrv6hQDs2bsfgJSUFN7+4BNuvaGzn1qe2R3dr2PahNFMmzCa9q2vZOqsP9qy+czH/uWXMHv+IgCmzPqG2JZnvxBg77796Y6FpavWUv3CyrnToPPkj2PhDzPnLKRLh9b+a5ycN1Xssm8Z8BgQC0QCk3wPgMXAGDMbgfc97QK841t2CCjl10yB1i2uZOHiZXS47maKFS3K8EH/Sl32QO8neO7ZfsREl6Pvow/xeL+BvDZ6LPXq1KbH9aevEJ0zfyFXXdGU4sVOnxq4Z89e/tHHuy2PJ5mu13Sk1VVX+K9hOeymVyZQtUlriodH0WfBr8x/YwhrJ38Q6LT+stZXNWPhkhV0uOFO7/5/9qnUZQ882o/nnnmSmHJR9O3di8f7D+W1t96nXp2a9Oh2zTm33af/UFauWc++/Qdo1eVmHu51Lz26Be5HHaB18ybELV1Fxx49KVqkCMOfeTx1Wa8+zzL06UeJKRfJk//4G30GvMDIMeOpV7sG3a/tdNb1E/fspd+QV/CkpOCc4+rYlrRt0QyAV0Z/wNbfdmJmVCwfzeCnevu/4T651f49e/fRu99zgPf8sq4d29DySu9V0jPnLGDiZO9V9B3bXMWNXfPGBVatmzdl4dJVdOh+H8WKFmH4M31Slz3w+ACe+9djxJSLpO8/evL4gBG8NmYc9WrXoMd13vcicc9ebrr3EQ4fOUpIiDHuk6nM+mQMCUl76Tf0FTwej/dYaNcq9VjIS3LrWAA4dvw4S1auZfA/H/Z7u3JKiP2lgbF8wbI6HyEYmNlWvOfC9cZbeXvZN/97oKtzbquZHXbOlfTN7wkMdc5V9J2Dtx+4yzn3uW/5IOA2YBuQCCxwzr1jZjcBw4FjwJVZnWeX6i8OxeZngy6rEOgUAmrQyq2BTiGgXPLxQKcgAWIW3ANHzqUEOoWAsogafh3x+rZDiN9+Zy+bkxKQ0byg7djlNDMr6Zw7bGbF8Q7X9nLOfXteG1HHLmipY6eOXbBSx04dO3++3lo/duwaBahjp6HYnDPWd3FFUWDceXfqRERERP4idexyiHPu9kDnICIiImemq2JFREREJN9QxU5ERESCQhAU7FSxExERESkoVLETERGRoKBz7EREREQk31DHTkRERKSA0FCsiIiIBIVgqGYFQxtFREREgoIqdiIiIhIUTBdPiIiIiEh+oYqdiIiIBAXd7kRERERE8g1V7ERERCQoBEHBThU7ERERkYJCFTsREREJChYEl8WqYiciIiJSQKhiJyIiIkEhCAp2qtiJiIiIFBSq2ImIiEhwCIKSnSp2IiIiIgWEKnYiIiISFIKgYKeKnYiIiEhBoY6diIiISAGhoVgREREJCrpBsYiIiIjkG6rYiYiISFBQxU5ERERE8g1V7ERERCQ4BEE5KwiaKCIiIhIcVLETERGRoBAM59ipY5eHuEO7Ap1CwAxauTXQKQTUoKZVA51CQA2cOTPQKQRO4dKBziCgUo4mBjqFwNr4ZaAzCCi7cXSgUyhw1LETERGRoBAEBTudYyciIiJSUKhiJyIiIkEhGM6xU8VOREREpIBQxU5ERESCQ8Ev2KliJyIiIlJQqGInIiIiQUHn2ImIiIhIvqGOnYiIiEgBoaFYERERCQpBMBKrip2IiIhIQaGKnYiIiAQFXTwhIiIiIvmGKnYiIiISHFSxExEREZH8QhU7ERERCQpBULBTxU5ERESkoFDFTkRERIKCrooVERERkXxDFTsREREJCkFQsFPFTkRERKSgUMVOREREgkMQlOxUsRMREREpIFSxExERkaAQBAU7VexERERECgp17EREREQKCA3FioiISFDQDYpFREREJN9QxU5ERESCgip2IiIiIpJvqGInIiIiQSEICnaq2ImIiIgUFKrYiYiISHAIgpKdKnYiIiIiBYQqdkFg0Yq1DHv9A1JSUujepR297rwh3XLnHMNef5+45WspWqQwI57uTf061VOXezweuvf6J9FREYx54V/+Tv9Pcc4x7JVRLFyygqJFi/L8wKeoX7d2prjtO3fRp/9QDhw8xEV1avHikKcpXKhQ6vING3/glvt68+rwAVzdrjUATw95kQWLlxMZXpYvPn3fb23KDd2GvUPtNp05sieB0dc1CnQ6OW7R6k0MGzPZe+x3upJeN3dMt/yX7bt5+tWJbNqyg8fu6UrPm9oBcOLkKe586jVOnkrG40mhY4uGPHJnl0A04bwtWrmBYaMnett8TWt63dY13XLnHMPenEjcyvXez/tTD1C/VlUAPpz0FZO+XIiZUataJUb0vZ8ihQvz1cKVjBo/hZ9/28V/Rw2kQZ1qAWjZ+Vu05geGvzuNFE8K3Ts244HusemW/7IjgX+N/JRNP+/gsbuu4b4b2qRb7vGk0KPPa0RHluHtZ3v6L/EcsujHPQz/4idSUhzdm1TkgTZV0y2fuymR1+f8QohBaIjxdNfaXF61LCdOebhr7LecTE4hOcXR6eJoHu5QPesXyWeCoGCXMxU7M7vXzEblxLbSbPN6M7sozfQQM2ufw6/Rxsy+yMlt5jUej4chr77LOy/154vxrzJz7mK2bN2eLiZu+Vq27djF7I/fYEjfBxn877Hplo+fNIvqF1byZ9p/WdzSFWz9bSdffz6Bof/qw6DnX8sy7uVRY7n39u58/fkESpcuxaRps1KXeTweXh41lhZXNE63zo1dO/Hu68/nZvp+s27KOD56oOu5A/MhjyeFIaM/450hD/HF2/2ZuXANW37blS6mTKkSPPNgd+67Kf0PfuFCYXw44hGmvfk0U0b1Y/Hqzaz74Vd/pv+neDwpDHljPO8Mf4Iv3hvBzPnL2bJtZ7qYuJUb2LZzN7PHvciQx//G4JHjAIhP2suEqXOYNHowM94dToonhZnzVwBQq2olXh/0CI0b1PF7m/4sjyeFoWOmMHbg/cx4sy8z49ay5bfd6WLKlCxG/17dMnXo/jBhxiKqV47J/WRzgSfFMXT6j4z9W0NmPH4FM9fHsyX+cLqYK2qEM/WRpkx5pBnDbqrHgM83A1A4LIQP7m/E1EebMeWRpiz+aQ/rfjsQiGbIn5CXh2KvB1I7ds65Z51z3wQunfxpw+YtVLmgPJUrxlC4UCE6t7uKuYtXpYuZu3gV3Tq1wcxoWL82Bw8fJSFpHwC7E/awcNkaenRpF4j0/7S5C5dyfZcO3jY1uIiDhw6TkLQnXYxzjuWr1tIp1luJu6FLR+YuXJK6fMKnU+jUthWR4eHp1mty2aWUKV069xvhB9tWL+bYgb2BTiNXbPhpG1UqRlG5QhSFC4XRudXlzF32XbqYyLKlaFD7QsJCQ9PNNzNKFCsCQHKyh2SPByPv/6m/4cdfqFIxhsoVo71tbtOMuUu+TRczd+m3dOtwlfezcVFN7+d9z37A2xk6fuIkyR4Px06cJDqyLAA1LqxI9coV/Nyav2bD/36jSoVIKpeP9L4XLRsyb8XGdDGRZUvRoFYVwkIz/xTuTtrPwtWb6d6hqb9SzlEbth+kSmQxKkcUo3BYCJ0vjWHe5qR0MSWKhKXe1+3oyZTUI9zMKFHEO6CX7HGcSnH54OjPHjPz2yNQstWxM7M7zWylma0zszFmFmpmfzOzn8xsIXBVmtgPzax7munDaZ4/ZWbfmdl6M3veN+8BM1vlmzfZzIqbWXPgOuAl32vWSLtdM2tnZmt923rfzIr45m81s8Fm9q1vWV3f/KZmttS3zlIzO+efnWfZ1iAzezJN3PdmVtX3+MHM3vXNm2hm7c1siZn9z8wC8u0Qn7SXCtFRqdPly0USn7g3Q8weKkRHpomJIN7XCRr+xgc8+dBdWEj++ljHJyZRPiY6dbp8dDniE9J/qe07cJDSpUoSFhaaKSY+IZFvFizm1puu9V/SkqPi9+ynQtTpTnn5qLLE+zow2eHxpHB97+e56vanad6oLpfWrZrzSeaw+KR9VIiOSJ0uXy6C+D37MseUy/h530dMVAT39biG2Nv70PLmRylVojgtGjfwW+45LWHPAcpHlU2djokqS/ye7FedRrw7jSfv7UpIPvvu+0PCweOUL1M0dTqmdBHiD5zIFDdnYwKd/72Mh8at47mbUmspeFIcN7y+ghbDFtG8ZgSXVinjl7zlrztnx87M6gG3AFc55xoCHuBOYDDeDl0H0lTWzrKda/BW4Zo55y4FXvQt+tw518Q3bzPQ0zm3FJgO9HXONXTO/ZxmO0WBD4FbnHMN8J4n+FCal0pyzl0GvAX80QH7AWjlnGsEPAsMP1e+Z9nW2dQERgKXAHWB24EWvnUDc3Kac5lmZfpLInMIZsb8pauJDC/DxXVq5FJyucdlq91njhn27zd58uFehGao5Eg+cobjOrtCQ0OYOqofC8YPZcNP2/hp6+85mFwuyeqYzlhryfJ9gQOHjjB36bd889HLxH36GseOn2D6N0syB+cTWbwV2d7/81dtIqJMSerXzF+noKSVRfOzPL+sQ/1oZvW5kjfuuoTX56T+1BIaYkx5pBnz+13FdzsO8NPuw5lXzofM/PcIlOxcPNEOuBxY5ftQFAOaAwucc4kAZvYpkPnM9PTaAx84544COOf+KBtdbGbPAWWBksDsc2ynDvCrc+4n3/Q44B/Aa77pz33/rgFu9D0vA4wzs1p4j/fTZ8efXVbbOptfnXPfAZjZRmCuc86Z2XdA1axWMLNeQC+At196ll53dc8q7E+LKRfJrjSVqt2Je4hOU8U4HbMnTcxeoiMjmL1gOfOWrGLh8m85efIUh48cpe/Qkbw04NEczTGnTPzvVP47dSYADS6qw+74hNRluxMSiU5TpQAIL1uGg4cOk5zsISwsNF3M95t/ok//oQDs23+AhUtXEBYaSvs2LfzUGvmrYqLKsivpdLVqd9J+oiPOv+pQumRxmjaoyaI1m6ldtWJOppjjYspFsCvhdEXe+1kumyEmnF2JGT/v4Sz7diOVypcjoqz3NIMOLS5n7cYtXNf+KvKjmKgy7E7anzodn7Sf6IjsnUKxdtNW5q/cRNyaHzh5MpnDR4/z1Csf8+ITt+dStjkvpnRRdh84njodf/AE0aWLnDG+SbVwtu/dxL4jJwkvUTh1fulihWhaLZzFP+2hdvmSuZqz5IzsDMUaMM5XOWvonKsDDCLrPwgAkv/Yrnl7gn8cIXaGdT4Eevuqb4OBolnEZMznbP6oNXs43XEdCsx3zl0MXJvVa5jZbN+w77vn2FZq+3yKZhEPkJJmOoUzdKKdc2Odc42dc41zulMH0KBuTbbt2MWO3+M5eeoUs+YuIfaqJuliYls0ZtrsBTjnWLfxJ0qVKE50VDhP/P0OFk4ey7z/vsUrAx+j2WUX59lOHcAdN1/PtI/fYdrH79C+TQumzpzjbdN3myhVsgTRUek7dmZGs8YNmT1vIQBTZn5NbCvvj9i8aR8zb/p/mDf9P3SKbc3Afz6qTl0+06B2Fbb9nsiO3UmcPJXMrLg1xF6RvaHFvQcOcfDwUQCOnzjJsnU/Ur1S3j+JvkGdamzbGc+OXYneNi9YQWzz9Fc7x17ZiGlzlng/G5u2UKpEMaIjy1IhOpL1m7dw7PgJnHMsW7uJ6lXydkf2bBrUqsy235PYsXuP971YtI62zepna90+93RmwQcDmPtuf17pewfNLqmZrzp1AA0qlWJb0lF27D3GyeQUZq2Pp229qHQx25KOpo5ubNx5kFMeR9nihdh7+CQHj50C4PgpD8t+3ku1ciX83oZcEQQlu+xU7OYC08zsVedcgplFAGuBkWYWCRwEegDrffFb8Vb4/gt043R17GvgWTP72Dl31MwifFW7UsAuMysE3AH8cQnXId+yjH4AqppZTefcFuAuYOE52lAmzXbvzSrAOdfpHNv4w1agK4CZXQbk6ev+w8JCGfDY/fR88jlSUlK4qXMstapV5pNp3sLord060fqKy4hb9i0db+tN0SJFGP70/wU467+u9VXNWLhkBR1uuJNiRYsy/NmnUpc98Gg/nnvmSWLKRdG3dy8e7z+U1956n3p1atKj2zXn3Haf/kNZuWY9+/YfoFWXm3m417306NY5N5uTa256ZQJVm7SmeHgUfRb8yvw3hrB28geBTitHhIWGMuChHvR8ZjQpKY6bOl5BrQsr8MnMxQDc2qUFiXsP0v3Rlzh89DghIcb4qQuYOeZfJO49SL9XPsKTkoJzjqtbNqJts4sD3KJzCwsNZcDDd9Gz30vez/vVrahVtRKfzJgHwK3XxtK62aXErdxAx7v7ej/vfe8H4NJ6NejYqgk3PjSQsNAQ6tW8kFu6tAFgzuLVPDfqI/YeOMSD/f9N3RpVeO+FvoFqZraEhYbyzN9v4P5B75CS4rixfRNqVSnPJ18uBeDWa5qTuO8gPfqMPL3/py/iizf7UrL4ueoLeV9YaAjPXFeH+99fS4qDGxtXoFZMST5ZsQOAW5tV4uuNCUz7djeFQo0iYSH8+7aLMTMSD53g6c824XGQ4hxXN4jO1CmUvMuyOhcpU5DZLcDTeCtVp/AOfdbzzdsFrANCnXO9zSwGmOaLnQs87Jwr6dtOP+Bu4CQwyzn3LzN7CHgK2AZ8B5Ryzt1rZlcB7+CtenUHBgBfOOcmmVk74GW8HdNVwEPOuRNmthVo7JxLMrPGwMvOuTZmdiXeIdtEYB5wl3Ouqpm1AZ50zmW638NZtlXM175o32u3AP7oDXzhqwpiZh+mybdq2mVn4uK/O/fOKKCsWMS5gwqwQU2rBjqFgBo4c2agUwicwgXjCus/yx1NDHQKgbXxy0BnEFAhN472a2lrX68Iv/3Oho/dG5CyXbY6duIf6tgFL3Xs1LELVurYqWPnz9fb//dIv/3Olh2z55xtM7Or8V50GQq865zLdJNUXxHqNbwjoEnOudZn26b+5wkRERERPzOzUOBNvHcX2YH3ItXpzrlNaWLKAqOBq51zv5lZdJYbS0MdOxEREQkKeey/FGsKbHHO/QJgZp/gvTZhU5qY2/HeFu43AOdcQqatZJCX/+cJERERkYLqAiDt//G5wzcvrdpAuJktMLM1Znb3uTaqip2IiIgEBX/+V19p71PrM9Y5l/Y/Y88qmYznAIbhvdNIO7z3EV5mZsvT3Ms3E3XsRERERHKYrxM39iwhO4DKaaYrARn/i5sdeC+YOAIcMbM44FLgjB07DcWKiIhIcDA/Ps5tFVDLzKqZWWHgVrz/nWpa04CWZhZmZsWBZnj/+9UzUsVORERExM+cc8lm1hvvf6UaCrzvnNtoZg/6lr/tnNtsZl8BG/D+L1bvOue+P9t21bETERGRoGAheWug0jk3C5iVYd7bGaZfAl7K7jbzVgtFRERE5E9TxU5ERESCQx67kV1uUMVOREREpIBQxU5ERESCgyp2IiIiIpJfqGInIiIiQcGs4NezCn4LRURERIKEOnYiIiIiBYSGYkVERCQ46OIJEREREckvVLETERGR4KCKnYiIiIjkF6rYiYiISFAwVexEREREJL9QxU5ERESCg25QLCIiIiL5hSp2IiIiEhQsROfYiYiIiEg+oYqdiIiIBAddFSsiIiIi+YUqdiIiIhIcdFWsiIiIiOQXqtiJiIhIUND/PCEiIiIi+YY6diIiIiIFhIZi85JTRwOdQcC4QsUDnUJADZw5M9ApBNTgLl0CnULADFrxS6BTkABylS4JdArBRUOxIiIiIpJfqGInIiIiwUEVOxERERHJL1SxExERkaBgukGxiIiIiOQXqtiJiIhIcNA5diIiIiKSX6hiJyIiIkHBQlSxExEREZF8QhU7ERERCQ66KlZERERE8gtV7ERERCQ46KpYEREREckvVLETERGRoGCq2ImIiIhIfqGOnYiIiEgBoaFYERERCQ4aihURERGR/EIVOxEREQkOukGxiIiIiOQXqtiJiIhIUNDtTkREREQk31DFTkRERIJDiCp2IiIiIpJPqGInIiIiQcF0VayIiIiI5Beq2ImIiEhw0FWxIiIiIpJfqGInIiIiwUEVOxERERHJL1SxExERkaCg/3lCRERERPINdexERERECggNxYqIiEhwCIIbFKtjV0AtWrmBYW9+REpKCt07t6bXbdemW+6cY9ibHxG3Yj1FixRhxFMPUL92VX7Zvos+Q99Mjdu+K4FH7r2Re266mseHjuLX7bsBOHj4KKVLFmfq2Of82q6zcc4x7NUxxC1dRdGiRRgxoA/169TMFLfj9930GfA8Bw4e5qI6NXhh4JMULlTojOufOHGSOx96ipOnTuHxeOjYtgWPPHAnACPHjGfuouWEhIQQEV6GEc/0IaZcpL+bflaLVm9i2JjJ3mOh05X0urljuuW/bN/N069OZNOWHTx2T1d63tQOgBMnT3HnU69x8lQyHk8KHVs05JE7uwSiCbmm27B3qN2mM0f2JDD6ukaBTidHOOcY9sqbLFy6kqJFi/D8s09Rv26tTHHbd+6izzPDOHDwEBfVqcmLg/tRuFAhvlm4hJFjPiTEQggNDeVffR6iccMGADw99CUWLF5BZHhZvvjkXX83LVsWrdzAsNETvcf7Na3pdVvXdMu9330TiVu5nqJFCnu/+2pVBeDDSV8x6cuFmBm1qlViRN/7KVK4MC+O+YT5y9dRKCyUKhWjGd73fkqXLBGA1p2fRRu2MnzCAu970eZiHri2abrlM5Zs5t2ZqwEoXqQQA+9tR90Ly7FrzyH6jfmKpANHMYOb2zbg7k6XBaAF8mcUmK6rmVU0s0m+5w3NrHM21mljZl/k0Os3NrPXc2Jbf5XHk8KQ18fzzogn+eL955k5bzlbtu5MFxO3cgPbdsQze/xLDOnzNwaP/BCA6pUrMHXsc0wd+xyT3xpCsSJFaN+iMQCvDuiduqxjy8Z08M3PK+KWrWbb9p3M/uxdhvR7hMEvjsoy7uU33+eeW29g9mfvUrpUSSbP+Pqs6xcuXIgPR41g2oQ3mTJ+FIuXr2bd9z8A0PPO7kz/aDRTx4+izVVNGf3+x/5pbDZ5PCkMGf0Z7wx5iC/e7s/MhWvY8tuudDFlSpXgmQe7c99NsenmFy4UxocjHmHam08zZVQ/Fq/ezLoffvVn+rlu3ZRxfPRA13MH5iNxS1eydftOvp48jqFPP86gF0ZmGffyqHe497ab+HryOEqXKsWkaV8CcGWTy5g+cSzTJo5h+IAneWbYv1PXubFLJ94dOcIv7fgzPJ4UhrwxnneGP8EX741g5vzlbNmWxXffzt3MHvciQx7/G4NHjgMgPmkvE6bOYdLowcx4dzgpnhRmzl8BQPPL6zPj3WFMf2cYVSuVZ+x/cuRnI1d5UlIYOm4eY/tez4wX7mHmsh/ZsnNPuphK5cowvn8Ppg2/i4eub8bA978BIDTUeOr2Vsx84R4+HXgbH3+zPtO6+ZaZ/x4BUmA6ds65351z3X2TDYFzduxy+PVXO+ce8edrnsmGH36mygXRVK4YTeFCYXRuewVzl36bLmbukm/p1vEqzIyGF9Xk4OGjJOzZny5m2dqNVK4YzQUxUenmO+f4auFKusRekdtNOS9z45bT7Zp23jZdXJeDh4+QkLQ3XYxzjuVrNtCpbQsAru/cnm/ilp11fTOjRPFiACQnJ5Oc7En9zJYsUTx128eOHc9zV1xt+GkbVSpGUblClPdYaHU5c5d9ly4msmwpGtS+kLDQ0HTzzYwSxYoAkJzsIdnjwchb7furtq1ezLEDe88dmI/MjVvK9Z07eI/jBhdx8NBhEpLS/yg751i+eh2dYlsBcEOXjsxduASAEsWLpR7HGY/pJpddQpnSpfzUkvO34cdfqFIx5vR3X5tmzF2S4btv6bd065D1d5/Hk8LxEydJ9ng4duIk0ZFlAWjRuEHq5+PSejXYnbjPn836Uzb8vJsqMWWpHF2WwmGhdL6iDvPW/JwuplHtipQpURSAS2tWYPe+QwBEly1J/aoxAJQoVpgaFSOI33vYvw2QPy3PdOzM7G4z22Bm681sgplda2YrzGytmX1jZjG+uEG+5fPM7H9m9oBvflUz+97MCgNDgFvMbJ2Z3WJmTc1sqW9bS82sTjby6WxmP5jZYjN7/Y/K3pm2lbb658vxfTNbYGa/mJlfO3zxSfuokGY4sHy5COKT9mWI2UuFchEZYtL/wM2avzzLztvq734kMrw0VSuVz+HM/5r4xCQqxJRLnS5fLor4xKR0MfsPHKR0yRKEhXm/pMtHR5GQuOec63s8Hq6/uzdXdb6d5k0bcWn9uqlxr749jjbd7uaLrxfwyAN35Vr7/oz4PfupEBWeOl0+qizxGTrwZ+PxpHB97+e56vanad6oLpfWrZrzSUqOik9Ionza4zi6HPEJ6T8H+w4cpHSpkqc/BzFRxCee7vzNmb+Yq3v8jb/36c/wZ570T+I5ID5pHxWiM3yv7cn43Zf192NMVAT39biG2Nv70PLmRylVojgtGjfI9BqTv1pEq6aZ5+c1CfsOUz7idCc8JqIk8fvO3DmbvOB7Wl5SLdP8nYkH2LwtkUtr5q3v+z/LzPz2CJQ80bEzs/pAfyDWOXcp8CiwGLjCOdcI+AR4Ks0qlwBdgCuBZ82s4h8LnHMngWeBT51zDZ1znwI/AK1823oWGH6OfIoCY4BrnHMtgHJpFmd3W3WBTkBTYKCZFTrDa/Uys9VmtnrsxKlnS+svyc4xlvZAPHkqmXlL13J1q6aZ4mbOW06XtlfmZHq5JuOHy7k/t35oaChTx49iwbTxbNj0Ez/9vDU15vEH72HBtPF07diGjybN+Ksp56ws2ns+XzihoSFMHdWPBeOHsuGnbfy09fccTE5yg8tip2fa51l8ENKGdGjbgq8++4A3XxzMyDEf5HSKuSerdmWsMmf5mYADh44wd+m3fPPRy8R9+hrHjp9g+jdL0sW9PXE6YaEhXNuueU5mnSuy+q4702d/xabtTI7byBO3tEg3/8jxkzzy+hf0u6M1JX3Ve8n78kTHDogFJjnnkgCcc3uBSsBsM/sO6AvUTxM/zTl3zBc/H2/n6WzKAJ+Z2ffAqxm2lZW6wC/OuT9OKPrPn9jWTOfcCV+OCUBMVkHOubHOucbOuca97rj+HGllT0xUOLvS/PW9O3Ev0ZHhGWIi2JW494wxi1au56JaVYmKKJNuvWSPhzmLVtO5bbMcyfWvmjhpBtff3Zvr7+5NdFQEu+ITU5ftTkwiOir9hQzhZUtz8PARkpM93piEJKJ9f73HlIs65/qlS5Wk6WUNWLR8TaZcunZsw5wFSzLND6SYqLLsSlOt3Z20n+gM+zQ7SpcsTtMGNVm0ZnNOpic5ZOJn0+h2x9/pdsffiY6KZHfa4zghMfUY/0N42TIcPHT49OcgPvOxDt6h19927GLv/gO524AcElMugl0JGb/XymaIyfr7cdm3G6lUvhwRZUtTKCyMDi0uZ+3GLalxU75ezPzl63jp6Qfz3CkXWYmJKMnuvYdSp+P3Hia6bOYLPn78LZEB781h1GPXEV6qWOr8U8keHn39C65tXpeOTTJffJNvhYT47xGoJgbsldMzMv8d9QYwyjnXAPg7UDTNsoyx56rDDAXmO+cuBq7NsC1vAmazfUO37/ry+dPb8jmR5rkHP16B3KBudbbtjGfHrkROnkpm1vzlxDZPf8VfbPNGTPt6Cc451m3aQqkSxdN9Ac6cl/Uw7LI1G6lWpQLl0wzjBtId3a9l6vhRTB0/inatrmTal3O9bfr+B0qVKEF0VPo8zYxml13C7PmLAZg66xvatfS2M7ZlsyzX37vvAAcPeYcwjh8/wbJV66h+YSUAtm4/fWL2vMUrqOabn1c0qF2Fbb8nsmN3kvdYiFtD7BXZG0bae+AQBw8fBeD4iZMsW/cj1Stl+feJBNgdPboxbeIYpk0cQ/vWVzF11hzvcfzdJkqVLJGp02ZmNLu8IbPnxQEwZebXxLb2VqG2bd+J85V7Nv7wP04lnyK8TGn/NuhPalCnWvrvvgUrMn/3XdmIaXPSfvcVIzqyLBWiI1m/eQvHjp/AOceytZuoXsU7GLRo5Qbe/WQmbw19jGJF80flqkH18mzbvY8dCQc4mexh1vIfaXtZ9XQxvycd5JGRM3jh71dTrcLpP+ydczzz7hyqV4zg3msu93fq8hflldudzAWmmNmrzrk9ZhaBtzL2x6/mPRniu5nZCKAE0AboBxROs/wQkPYM37TbujerBJxznf54bmbFgOpmVtU5txW45Xy2FWhhoaEMePhuev7zRVJSHDdd04paVSvxyYx5ANx6bSytm11K3Ir1dLyrL0WLFmZ43/tT1z92/ARL1nzP4Mf/lmnbM+cvp2ts3hyGbd28CXFLV9GxR0+KFinC8GceT13Wq8+zDH36UWLKRfLkP/5GnwEvMHLMeOrVrkH3azuddf3EPXvpN+QVPCkpOOe4OrYlbVt4K5avjP6Arb/txMyoWD6awU/19n/DzyIsNJQBD/Wg5zOjvcdCxyuodWEFPpnp7dje2qUFiXsP0v3Rlzh89DghIcb4qQuYOeZfJO49SL9XPjrd7paNaNvs4gC3KGfd9MoEqjZpTfHwKPos+JX5bwxh7eR8NPSYhdZXNWPh0pV0uPFuihUtwvABfVOXPfDYv3iufx9iykXR9+H7ebz/MF57+wPq1a5Jj+uuAWD2vEVMmzWHsLAwihYpzKvDnkmtUPV5Zhgr16xn3/4DtOp6Kw8/cA89ul0TkHZmxfvddxc9+71ESkoKN119hu++lRvoeHdf7+fc9913ab0adGzVhBsfGkhYaAj1al7ILV3aADB01AROnkrmvn++lBo7+LF7A9HEbAsLDeGZu2O5/6XPSUlx3NiqPrUqRfHJ3PUA3NruUkZPXcH+w8cZMs77/oSGGpOG3MG3P/3O9CWbqV05ihv6fwTAYz2uonXDzOfg5Tv5oNr6V5k735OOcomZ3YN3yNUDrAWm4B3q3AksB5o459qY2SCgIlADqAK86Jx7x8yqAl845y72dQxnA4WAEcBvwDggEZgH3OWcq2pmbYAnnXOZ7ndgZtcCLwFJwEogxjl3h5ldea5t+XI87Jx72bet74Guvk7iGbkdK/LGzgiE4lHnjinI9v187pgCbHCXgnV/vPMxaMUvgU4hoNzBnecOKsDcrnWBTiGgQpo+6NeeVsprrf32Oxvy2MKA9CLzSsUO59w4vB2mtKadIfwn51yvDOtvBS72Pd8LNMmwTu00zwf44hYAC87wGvOdc3XN+6fqm8Bq3zrLzrUt59ygDLkVrDKHiIhIfhQE//NEwW/hn/eAma0DNuIdfh0T2HREREREzi7PVOyyK2M1LBdf51W8Q8EiIiJSEATBOXaq2ImIiIgUEPmuYiciIiLyp+gcOxERERHJL1SxExERkeCgc+xEREREJL9Qx05ERESkgNBQrIiIiAQHXTwhIiIiIvmFKnYiIiISHHTxhIiIiIjkF6rYiYiISHDQOXYiIiIikl+oYiciIiLBQefYiYiIiEh+oYqdiIiIBAdV7EREREQkv1DFTkRERIKDrooVERERkfxCFTsREREJDjrHTkRERETyC1XsREREJDjoHDsRERERyQ1mdrWZ/WhmW8ys31nimpiZx8y6n2ub6tiJiIiI+JmZhQJvAtcAFwG3mdlFZ4h7AZidne2qYyciIiLBwcx/j3NrCmxxzv3inDsJfAJ0yyLuYWAykJCdjapjJyIiIpLDzKyXma1O8+iVIeQCYHua6R2+eWm3cQFwA/B2dl9XF0+IiIhIcPDjxRPOubHA2LOEZFXWcxmmXwP+6ZzzWDZv1aKOnYiIiIj/7QAqp5muBPyeIaYx8ImvUxcFdDazZOfc1DNtVB07ERERCQ556wbFq4BaZlYN2AncCtyeNsA5V+2P52b2IfDF2Tp1oI6diIiIiN8555LNrDfeq11DgfedcxvN7EHf8myfV5eWOnYiIiISHPLYDYqdc7OAWRnmZdmhc87dm51t5q0WioiIiMifpopdXhJaJNAZSKAULh3oDAJq0IpfAp1CwAxqVj3QKQTUwPmrAp1CYJW54NwxknPy1jl2uUIVOxEREZECQhU7ERERCQ557By73FDwWygiIiISJFSxExERkeCgc+xEREREJL9QxU5ERESCg86xExEREZH8Qh07ERERkQJCQ7EiIiISHHTxhIiIiIjkF6rYiYiISHDQxRMiIiIikl+oYiciIiLBQefYiYiIiEh+oYqdiIiIBAedYyciIiIi+YUqdiIiIhIcdI6diIiIiOQXqtiJiIhIcNA5diIiIiKSX6hiJyIiIsEhROfYiYiIiEg+oYqdiIiIBAddFSsiIiIi+YU6diIiIiIFhIZiRUREJDjodiciIiIikl+oYiciIiLBQRdPiIiIiEh+oYqdiIiIBAedYyciIiIi+YUqdiIiIhIcVLETERERkfxCFTsREREJDkFQsVPHroBatGIdw0Z9SIonhe5dYul1x/XpljvnGPbGh8QtX0vRokUY0e8h6teuDkDsLb0pUbwooSEhhIaGMnnsCAAeH/wav/72OwAHDx+ldMniTH3vRb+262yccwx7dQxxS1d52zSgD/Xr1MwUt+P33fQZ8DwHDh7mojo1eGHgkxQuVOis68fecC8lihcjNDSU0NAQJn/wOgA//O8XBr44iqNHj3FBhRheHvwUJUsU92u7s7Jo5QaGjZ5ISkoK3a9pTa/buqZb7pxj2JsTiVu5nqJFCjPiqQeoX6sqAB9O+opJXy7EzKhVrRIj+t5PkcKF+WrhSkaNn8LPv+3iv6MG0qBOtQC07Nyccwx75U0WLl1J0aJFeP7Zp6hft1amuO07d9HnmWEcOHiIi+rU5MXB/ShcqBDfLFzCyDEfEmLe4/9ffR6iccMGADw99CUWLF5BZHhZvvjkXX83Lcd1G/YOtdt05sieBEZf1yjQ6eSI3PjuA5jw+ZdMnDKbsNBQWl/RiL4P3unPZv0pi9b8wPB3p3nfi47NeKB7bLrlv+xI4F8jP2XTzzt47K5ruO+GNqnL2t0/jBLFivjeixAm/fsxv+Yuf16B7NiZWUXgdedcdzNrCFR0zs06xzptgCedc12zWLbAt2x1zmeb8zyeFIaMfJ/3X+5PTLlIejz4NLFXNaZm1UqpMXEr1rFtx25mTxzJ+k3/Y/Cr7/Hft4alLh//6rOEly2dbruvDnws9fnzo8dTKg90YNKKW7aabdt3Mvuzd1m/8UcGvziK/773Wqa4l998n3tuvYEuHVoz8IU3mDzja267scs51x//5vOEly2TblvPjBjJU73vp+llDZg842ve+2gSj/797lxu6dl5PCkMeWM877/wFDHlIujxj0HENm9EzQsvSI2JW7mBbTt3M3vci6zf/DODR47jv6MGEp+0lwlT5zDzvREULVKYx4aMYub8FdzYqSW1qlbi9UGPMPDVDwPXuGyIW7qSrdt38vXkcaz/fjODXhjJZx+MyhT38qh3uPe2m+jSsS3PjniNSdO+5Pbu13Flk8to16o5ZsYP//uFx/41lK8++wCAG7t04s4e1/PPQS/4u1m5Yt2UcaycOJobnn8/0KnkiNz67lu+9nvmLV7N9PdeonDhQuzZd8BvbfqzPJ4Uho6ZwntDehETWYabnxhJ26YXUbNK+dSYMiWL0b9XN+Yu35jlNsYNe4jw0iX8lbJ/6D52+ZNz7nfnXHffZEOgcwDT8bsNP2yhygUxVK4YQ+FCYXSObc7cJavSxcxdsopunVphZjSsX5uDh4+QsGdftrbvnOOr+cvp0u6q3Ej/T5sbt5xu17Tztuniut42Je1NF+OcY/maDXRq2wKA6zu355u4ZdleP6Nft+2gSaOLAWjetBFfL1iSCy07Pxt+/IUqFWOoXDHau//bNGPukm/Txcxd+i3dOlzlbetFNTl4+CgJe/YD3h+E4ydOkuzxcOzESaIjywJQ48KKVK9cwc+tOX9z45ZyfecO3rY1uIiDhw6TkLQnXYxzjuWr19EpthUAN3TpyNyF3n1XongxzPflf+zY8dTnAE0uu4QypUv5qSW5b9vqxRw7cPZjPD/Jre++T6bN4YHbu1G4cCEAIsPLnDU+L9jwv9+oUiGSyuUjve9Fy4bMW5G+AxdZthQNalUhLLRAdgWCVp7cm2Z2t5ltMLP1ZjbBzK41sxVmttbMvjGzGF/cIN/yeWb2PzN7wDe/qpl9b2aFgSHALWa2zsxuMbOmZrbUt62lZlbnPHO7zcy+823/Bd+8UDP70DfvOzN73Df/ETPb5GvLJzn7Lp1ZfOJeKpSLTJ0uXy6S+MR9GWL2ZRHj/YI3g559h3Fjr358OuObTNtfvWEzkeFlqFopb/3IxycmUSGmXOp0+XJRxCcmpYvZf+AgpUuWICws1BsTHUVC4p5zrm9m9Hz0GW689xE+nfplakyt6lWZt2g5AF/NW8SuhPSvFwjxSfuoEB2ROl2+XATxGX644pMy7v8I4pP2ERMVwX09riH29j60vPlRSpUoTovGDfyWe06IT0iifNr9GF2O+Az7Zd+Bg5QuVfL0cRATRXzi6c7fnPmLubrH3/h7n/4Mf+ZJ/yQuf1luffdt3b6L1d/9wM0P9efORwfx3Q9bcrklf13CngOUjyqbOh0TVZb4PdmvNBrQ89mx3PT4q/z3q+U5n2CgWIj/HgGS54Zizaw+0B+4yjmXZGYRgAOucM45M7sfeAp4wrfKJcAVQAlgrZnN/GNbzrmTZvYs0Ng519u3/dJAK+dcspm1B4YDN2Uzt4rAC8DlwD7gazO7HtgOXOCcu9gXV9a3Sj+gmnPuRJp5GbfZC+gF8PaLz9Drzmylcg4ui9fJTow36ONRQ4iJimDPvgPc9+RzVK9SkSaXXpQaN3PuUrq0a54DeeY+y9Bwl7nZ2Vr/4zEvE1Mukj1793Pfo/2pfmElmjRqwPD+j/Hcq2/z5vv/IbZlMwqF5YGPVBaNNDIcAFm8D2Zw4NAR5i79lm8+eplSJYvz2JA3mf7NEq5rn7eqs2fjznJsnw46+2ekQ9sWdGjbglXfbmDkmA/48M2XcjpNyRW5893n8Xg4eOgIn45+ju9++JnHBr3GN/95I/NxlYdk9V13Pvl+/EJvoiPLsGf/IXo+O5ZqlcrR5OIaOZih5JY88CuUSSwwyTmXBOCc22tmDYBPzawCUBj4NU38NOfcMeCYmc0HmgLrzrL9MsA4M6uF9xNe6DxyawIscM4lApjZRKAVMBSobmZvADOBr33xG4CJZjYVmJrVBp1zY4GxAG7XuvPsdmQtplwku9JUH3Yn7iE6KjxDTMQZY2KivNWeyPAytG/RlA2bf07t2CUne5izaCWTx4wgL5g4aQafTZ8NQIN6tdgVn5i6bHdiEtFRkeniw8uW5uDhIyQnewgLC2V3QhLRvr/eY8pFnXH9GF9MZERZ2re+kg2bfqJJowZUr1qZ90d6z8/59bcdLMww7BMIMeUi2JVwenhtd+Le1OHU0zHhGfb/XqIjw1n27UYqlS9HhO8cow4tLmftxi15vmM38bNp/Heq9zTaBhfVZnfa/ZiQmLqP/xBetgwHDx0+fRzEZz5WwDv0+tvgXezdf4CIsnl/+C3Y5dZ3X0y5SDq0bIqZcUm9moSEhLDvwKHUz0leFBNVht1J+1On45P2Ex2R/XyjI73He2TZUrS/4mK++9/2gtGxC4KrYvNiC43Mf1K9AYxyzjUA/g4UTbMsY+y5OkdDgfm+6tq1GbblTcBstm/oNuNlb1n+ueOc2wdcCiwA/gH8sV4X4E28Fb41ZuaXjnSDOjXYtmM3O3YlcPJUMrPmLSW2eeN0MbHNGzNtdhzOOdZt/IlSJYoTHRnO0WPHOXz0GABHjx1nyeoN1K5WOXW9ZWu+o1qVipSPzvwjGAh3dL+WqeNHMXX8KNq1upJpX871tun7HyhVogTRURHp4s2MZpddwuz5iwGYOusb2rW8AoDYls2yXP/oseMcPnIU8L0nK9ZSu/qFAOzZux+AlJQU3v7gE269IfCnczaoU41tO+PZsSvRu/8XrCC2eforHmOvbMS0OUu8bd20hVIlihEdWZYK0ZGs37yFY8dP4Jxj2dpNVK9SMUAtyb47enRj2sQxTJs4hvatr2LqrDnetn23iVIlS2TqtJkZzS5vyOx5cQBMmfk1sa29Veht23fifOWOjT/8j1PJpwgvk3d/wOW03Prua9+iCSvWes9P+3X775w6lUx4mbx9rmWDWpXZ9nsSO3bv8b4Xi9bRtln9bK179PgJjhw9nvp8ybqfqJXmogvJ2/JixW4uMMXMXnXO7fENxZYBdvqW35MhvpuZjcA7FNsG7/Bn4TTLDwFpP4Fpt3VvVgk45zqdIbcVwEgzi8I7FHsb8IZv+qRzbrKZ/Qx8aGYhQGXn3HwzWwzcDpQE9p+t8TkhLCyUAY/eR8++w0lJSeGma9pQq1plPpk2B4Bbu3Wg9RWNiFuxlo53PErRIoUZ/s+HANiz7wC9B7wMeE+i79ruKlo2a5i67ZnzltI1Nm9Wb1o3b0Lc0lV07NGTokWKMPyZx1OX9erzLEOffpSYcpE8+Y+/0WfAC4wcM556tWvQ/dpOZ11/z9599O73HAAej4euHdvQ8krvj8XMOQuYOPkLADq2uYobu3bwZ5OzFBYayoCH76Jnv5e8+//qVtSqWolPZswD4NZrY2nd7FLiVm6g4919vW3tez8Al9arQcdWTbjxoYGEhYZQr+aF3NKlDQBzFq/muVEfsffAIR7s/2/q1qjCey/0DVQzz6j1Vc1YuHQlHW68m2JFizB8wOkcH3jsXzzXvw8x5aLo+/D9PN5/GK+9/QH1atekx3XXADB73iKmzZpDWFgYRYsU5tVhz6QOYfV5Zhgr16xn3/4DtOp6Kw8/cA89ul0TkHbmhJtemUDVJq0pHh5FnwW/Mv+NIayd/EGg0/rTcuu778bOben/wltce+8TFCoUxvNP/1+eHoYF7/fAM3+/gfsHvUNKiuPG9k2oVaU8n3y5FIBbr2lO4r6D9OgzksNHjxMSYoyfvogv3uzLvoNHeHj4hwAke1Lo2roRLS+vG8DWyPkwd74nHfmBmd0D9AU8wFpgCvAq3g7ZcqCJc66NmQ0CKgI1gCrAi865d8ysKvCFc+5iX8dwNt4h1xHAb8A4IBGYB9zlnKua3dudmNntwNN4q3eznHNPmdmlwAecroA+DXwDzMfbkTTgI+fc82drd04NxeZLRfL2X7+57kjiuWMKMCt9wbmDCqhBzaoHOoWAGjg/8KcvBJI7uD3QKQRUSJ1r/dpDTpn1T7/9zoZ0fiEgvf+8WLHDOTcOb+crrWlnCP/JOdcrw/pbgYt9z/fiPTcurdppng/wxS3AO5SaVT5t0jz/GPg4w/L1wGVZrNriDDmLiIiI5Lg82bETERERyXFBcPFEvu7YOecGBToHERERkbwiX3fsRERERLItCCp2Bb+FIiIiIkFCFTsREREJDqrYiYiIiEh+oYqdiIiIBIc8fmPpnKCKnYiIiEgBoYqdiIiIBAedYyciIiIi+YUqdiIiIhIcVLETERERkfxCFTsREREJDiEFv55V8FsoIiIiEiTUsRMREREpIDQUKyIiIsFBNygWERERkfxCFTsREREJDrrdiYiIiIjkF6rYiYiISHBQxU5ERERE8gtV7ERERCQ46KpYEREREckvVLETERGR4KBz7EREREQkv1DFTkRERIKDKnYiIiIikl+oYiciIiLBQRU7EREREckvVLETERGR4KD72ImIiIhIfqGOnYiIiEgBoaHYvCT5WKAzCBgrWibQKQRUytHEQKcgATJw/qpApxBQg9s2CXQKAfXsh68FOoXgoosnRERERCS/UMVOREREgoMqdiIiIiKSX6hiJyIiIsFBtzsRERERkfxCFTsREREJDjrHTkRERETyC1XsREREJDioYiciIiIi+YUqdiIiIhIcVLETERERkfxCFTsREREJDiG6j52IiIiI5BPq2ImIiEhwsBD/PbKTjtnVZvajmW0xs35ZLL/DzDb4HkvN7NJzbVMdOxERERE/M7NQ4E3gGuAi4DYzuyhD2K9Aa+fcJcBQYOy5tquOnYiIiIj/NQW2OOd+cc6dBD4BuqUNcM4tdc7t800uByqda6O6eEJERESCgx9vd2JmvYBeaWaNdc6lrbhdAGxPM70DaHaWTfYEvjzX66pjJyIiIpLDfJ24sw2dZnWJrssy0Kwt3o5di3O9rjp2IiIiEhzy1g2KdwCV00xXAn7PGGRmlwDvAtc45/aca6N5qoUiIiIiQWIVUMvMqplZYeBWYHraADOrAnwO3OWc+yk7G1XFTkRERIKD5Z0bFDvnks2sNzAbCAXed85tNLMHfcvfBp4FIoHR5s092TnX+GzbVcdOREREJACcc7OAWRnmvZ3m+f3A/eezTXXsREREJEjknYpdbtE5diIiIiIFhCp2IiIiEhzy1lWxuaLgt1BEREQkSKhiJyIiIsEhD10Vm1tUsRMREREpIFSxExERkSBR8OtZBb+FIiIiIkFCFTsREREJDjrHTkRERETyC3XsRERERAoIDcWKiIhIcAiCoVh17AqoRSs3MGz0x6SkpND9mlb0uq1ruuXOOYa9OZG4lRsoWqQwI566n/q1qgLw4aTZTPpyIWZGrWqVGNG3J0UKFwZgwpQ5TJw2l7DQEFo3u5S+vW7xd9OyxTnHsH+/xcJlqyhapAjPD3iC+nVrZYrb/vtu+jwzggMHD3FRnZq8OKgvhQsV4uet2/nXc6+w8cefefzBe+h5R3cATpw4yR0PPcnJk6fweDx0im3JIw/c5e/mnZdFa35g+LvTSPGk0L1jMx7oHptu+S87EvjXyE/Z9PMOHrvrGu67oU265R5PCj36vEZ0ZBnefran/xL/k7zH/kTfsd/6LMf+et+x/0CaY/+rDMf+/RQpXJgXx3zC/OXrKBQWSpWK0Qzvez+lS5YIQOvObdGKdQwb9aF3f3eJpdcd16db7pxj2BsfErd8LUWLFmFEv4eoX7s6ALG39KZE8aKEhoQQGhrK5LEjUteb8PmXTJwym7DQUFpf0Yi+D97pz2blim7D3qF2m84c2ZPA6OsaBTqdHLdow1aGT4wjJcXRvXV9HujaON3yGUt/4N2ZawAoXrQQA+9pS90q5ThxMpm7hk/mZLKHZE8KnZrU5OEbrwhEE+RP+EtDsWZW1cy+z6lkChIzG2RmTwbitT2eFIa8MYF3hvfhi/eGM3P+CrZs25kuJm7lBrbtjGf2uBcY8vi9DB45HoD4pH1MmDqHSaMHMePdYaR4Upg5fwUAy9dtZt7StUwfO5Qv3hvOfT2u8Xvbsitu2Sq2bv+drz97n6FPP8qgF0dlGffym+9x72038PWk9ylduiSTps8GoGzpUvTv8xA9b78pXXzhwoUYN+oFpn/0FlMnjGbRstWs+35zrrfnz/J4Uhg6ZgpjB97PjDf7MjNuLVt+250upkzJYvTv1S1Th+4PE2YsonrlmNxPNgd4j/3xvDP8Cb54bwQz5y8/w7G/m9njXmTI439j8MhxAMQn7fUd+4OZ8e7wdMd+88vrM+PdYUx/ZxhVK5Vn7H++8HvbssPjSWHIyPd554Wn+WLcv5k5bwlbtu5IFxO3Yh3bduxm9sSRDHniAQa/+l665eNffZap772YrlO3fO33zFu8munvvcQXH77Cfbdc65f25LZ1U8bx0QNdzx2YD3lSUhg6fgFjn+jGjBF3MnP5T2zZuSddTKVyZRj/r5uYNuwOHrquKQM/mAdA4UKhfNDvBqY+dztTht7G4u+2sW7LrkA0IxeE+PERGHnuHDsz80sV0cxC/fE6gbDhx1+oUjGGyhWjKVwojM5tmjF3ydp0MXOXrqVbh6swMxpeVJODh4+SsGc/4P1xOH7iJMkeD8dOnCQ6MhyAT6bP44Fbu1C4cCEAIsNL+7Vd52Nu3DKu79zO276L63Hw8GESktJ/qTnnWL56PZ3atgTghs7tmRu3FIDIiLJcclEdwsLSHyZmRonixQBITk4mOTkZI++W9jf87zeqVIikcvlI77HQsiHzVmxMFxNZthQNalUhLDTz18HupP0sXL2Z7h2a+ivlvyTrY//bdDFzl357Hsd+WQBaNG5AWKj3WLi0Xg12J+7zZ7OybcMPW6hyQQyVK8Z42x/bnLlLVqWLmbtkFd06tfK2v35tDh4+QsKes7fnk2lzeOD2bmk++2VyrQ3+tG31Yo4d2BvoNHLFhl/iqRJTlsrRZSgcFkrnZrWY9+0v6WIa1apAmRJFAbi0Znl27z0M+L7ninpHaZI9KZzypGBBMIRZUORExy7UzN4xs41m9rWZFTOzhma23Mw2mNkUMwsHMLMFZtbY9zzKzLb6nt9rZp+Z2QzgazOrYGZxZrbOzL43s5YZX9S3zjQz+8rMfjSzgWmW3WlmK33rj/mjE2dmh81siJmtAK5ME9/UzD73Pe9mZsfMrLCZFTWzX3zza/hea42ZLTKzur755cxsspmt8j2uyiLXB8zsSzMrlgPv9znFJ+2jQnRE6nT5cuHEZ/jijk/aR4VyGWKS9hETFc59Pa4m9vYnaHnzY5QqUYwWjS8GYOvO3az+/idu7j2EO/uM4Lsf0n9J5CXxiXsoH10udbp8dDniE9N37PYdOEjpUiVSO29ZxWTF4/HQ7a7/o/k1t9K86WVcenHdnE0+ByXsOUD5qLKp0zFRZYnfcyDb6494dxpP3tuVkJD88aWe+diPOMOxH5k+JmkfMVER3NfjGmJv70PLmx+lVInitGjcINNrTP5qEa2aZp6fF8Qn7s3QtkjiM3RC4xMztj+S+ERv58YMevYdxo29+vHpjG9SY7Zu38Xq737g5of6c+ejg/juhy253BL5qxL2HaZ8RMnU6ZiIksTvO3LG+MkLN9HykgtTpz0pKdww4GNaPPwuzetX4dIa5XM1X78x898jQHKiY1cLeNM5Vx/YD9wEjAf+6Zy7BPgOGHjm1VNdCdzjnIsFbgdmO+caApcC686wTlPgDqAh0MPMGptZPeAW4Crf+h5fDEAJ4HvnXDPn3OI02/kW+OMEi5bA90AToBmwwjd/LPCwc+5y4ElgtG/+SOBV51wTX9vfTZugmfUGrgWud84dy8b78Nc5l2lWpkMsqxgzDhw6wtyla/nmo5eI+/RVjh0/wfRvvFUsjyeFg4eO8OkbA3iq1y089txoXBbbyQuyyivTX5zZiclCaGgo0yaMZuH0j9iw6Ud++nnrn00z12W1e7L7l/f8VZuIKFOS+jUr5XBWuSjLYz/jfs+8mhm+Y/9bvvnoZeI+fc137C9JF/f2xOmEhYZwbbvmOZl1DsrqmM5OjDfo41FD+PydF3jnhaf5eOpsVq3fBHj/mDl46Aifjn6Opx68k8cGvZZnP/vilfVnP+vYFZu3MzluI0/ccrouERoSwpShtzP/1fv47pfd/LTj3H/0St6QE8Oevzrn1vmerwFqAGWdcwt988YBn2VjO3Occ3/UxFcB75tZIWBqmu1ntc4eAF/FrQWQDFwOrPJ9WRUDEnzxHmByxo0455LNbIuvU9gU+DfQCggFFplZSaA58FmaH8Uivn/bAxelmV/azEr5nt8F7MDbqTuVVQPMrBfQC+DtEU9lOtH5z4gpF8GuhNPDC7sT96UOp6aLScwYU5Zl326kUvkoIsp6h1k7tGjM2o1buK59c2KiwunQ4nLMjEvqVifEjH0HDqXGBtrESdP577SvAGhQrza7ExJTl+1OSCQ6KiJdfHjZMhw8dITkZA9hYaFZxpxN6VIlaXbZJSxavpraNarmSBtyWkxUGXYn7U+djk/aT3RE9vbX2k1bmb9yE3FrfuDkyWQOHz3OU698zItP3J5L2f51mY/9vanDqadjwtmVpjLrjQn3Hfvl0hz7l/uOfe+P3ZSvFzN/+To+fOmfeXZYKqZcZIa27SE6KqvPftYxMb7jPzK8DO1bNGXD5p9pculFxJSLpEPLpt7Pfr2ahISE5KnPvmQWE1EydWgVIH7vYaLLZr7g58ffkhjw3lzGPNmN8JKZB5VKlyhC07qVWLxhG7UrRWZanu/k0c9uTsqJit2JNM89QNmzxCanec2iGZal1oidc3F4O1Y7gQlmdreZ3eAbWl33x3Aumf/0dHiLU+Occw19jzrOuUG+5cedcx4AM5vt29YfFbZFwDXAKeAbvJ3EFkCcL+f9abbZ0DlXz7deCHBlmvkXOOcO+ZZ9D1QFzljycM6Ndc41ds41zolOHUCDOtXYtjOeHbsSOXkqmVkLVhDbPP0VX7FXNmTanCU451i3aQulShQjOrIsFaIjWb/5Z44dP4FzjmVrN1G9SgUA2l91GSvWeS8U+HXHbk4lewgvUyrT6wfKHd2vY9qE0UybMJr2ra9k6qy53vZ9v5lSJUsQHZX+S8nMaHb5JcyevwiAKbO+IbbllVltOtXeffs5eMj7ZXn8+AmWrlpL9Qsr506DckCDWpXZ9nsSO3bv8R4Li9bRtln9bK3b557OLPhgAHPf7c8rfe+g2SU183SnDrJ77Dc6y7G/JcOxXxHwXmn77iczeWvoYxQrWiSrl84TGtSpwbYdu9mxK8Hb/nlLiW2e/krI2OaNmTY7ztv+jT9RqkRxoiPDOXrsOIePegcVjh47zpLVG6hdzXtst2/RhBVrvedm/rr9d06dSs5Tn33JrEG1GLbF72dH4gFOJnuYteJ/tG1UPV3M73sO8cgbM3nh752oVv70HwB7Dx7l4BHvT/vxk8ks27SdahXT/4EgeVduXKhwANhnZi2dc4vwVq3+qN5txVtNWwl0P9MGzOxCYKdz7h0zKwFc5px7DJiSJuZioIOZRQDHgOuB+4CjwDQze9U5l+BbXso5ty3tazjnOmV42Ti8Q8jjnXOJZhYJlAc2Ouecmf1qZj2cc5+Z98/1S5xz64Gvgd7AS768GqapMK4F3gKmm1kn59zv2XoH/6Kw0FAGPHwnPfu9TEpKCjdd3ZJaVS/gkxneK55uvTaW1s0uJW7lBjre/RRFixRheF/vbSwurVeDjq2acONDAwkLDaVezSrc0qUNADde3Yr+L7/Htff3p1BYGM8/dX+erVy0bt6UhUtX0aH7fRQrWoThz/RJXfbA4wN47l+PEVMukr7/6MnjA0bw2phx1Ktdgx7XeQ+LxD17ueneRzh85CghIca4T6Yy65MxJCTtpd/QV/B4PDjnuLpdK9q2aBaoZp5TWGgoz/z9Bu4f9A4pKY4b2zehVpXyfPKld3j91muak7jvID36jOTw0eOEhBjjpy/iizf7UrJ4xr+98j7vsX8XPfu95Dv2W1GraqUzHPt9fcf+/UDGYz+EejUvTD32h46awMlTydz3z5dSYwc/dm8gmnhWYWGhDHj0Pnr2He5t/zVtqFWtMp9MmwPArd060PqKRsStWEvHOx6laJHCDP/nQwDs2XeA3gNeBrynXXRtdxUtmzUE4MbOben/wltce+8TFCoUxvNP/1+e/eyfj5temUDVJq0pHh5FnwW/Mv+NIayd/EGg08oRYaEhPHNXG+5/aRopKSnc2Ko+tSpF8sm87wC4NbYBo6euYP/h4wwZPx/wDr9OGnwrifuP8vQ7X+NJcaQ4x9VNa9G2YbVANicH5blrRnOc/ZXzJMysKvCFc+5i3/STQElgKvA2UBz4Bfibc26f74KD/wKHgXnAnc65qmZ2L9DYOdfbt517gL54q2eHgbudc79meO17gc54z5urCXzsnBvsW3YL8DTePXgK+IdzbrmZHXbOlSQLvgsb9gPXOue+NrOxQHnn3HW+5dXwdtIqAIWAT5xzQ8wsCngTqIe3oxznnHvQzAYBh51zL5tZJ+B5oINzLulM76fbvixoT1qxkgXkxNw/KSUhuO8aZMXLnTuooArLfx3onDS4bZNApxBQz374WqBTCKiQK/7h178QUn6Y7rff2ZC61wXkr5+/1LELpIydwYJAHbvgpY6dOnbBSh271wKdQkD5vWP34wz/dezqXBuQjl3Br0mKiIiIBIl8+1+KOec+BD4McBoiIiKSX1jBr2cV/BaKiIiIBIl8W7ETEREROT/5/2ruc1HFTkRERKSAUMdOREREpIDQUKyIiIgEhwJwY+1zUcVOREREpIBQxU5ERESCg253IiIiIiL5hSp2IiIiEhRM59iJiIiISH6hip2IiIgEiYJfzyr4LRQREREJEqrYiYiISHDQOXYiIiIikl+oYiciIiLBQRU7EREREckvVLETERGRIFHw61kFv4UiIiIiQUIVOxEREQkOOsdORERERPILVexEREQkOKhiJyIiIiL5hTp2IiIiIgWEhmJFREQkSBT8elbBb6GIiIhIkFDFTkRERIKDLp4QERERkfxCFTsREREJDlbw61kFv4UiIiIiQUIVOxEREQkSOsdORERERPIJc84FOgfxSVk6Mmh3htXtGugUAsoteCXQKQRWpUsCnUHglLkg0BkE1r7fAp1BQA2597FApxBQg3445dcSmtuxwm+/s1apWUDKg6rYiYiIiBQQOsdOREREgoOuihURERGR/EIVOxEREQkO+p8nRERERCS/UMVOREREgoQqdiIiIiKST6hjJyIiIlJAaChWREREgoNudyIiIiIi+YUqdiIiIhIkdPGEiIiIiOQTqtiJiIhIcNANikVEREQkv1DFTkRERIKEKnYiIiIikk+oYiciIiLBQefYiYiIiEh+oY6diIiISAGhjp2IiIhIAaFz7ERERCQ46Bw7EREREckvVLETERGRIKGKnYiIiIjkE+rYiYiIiBQQGooVERGR4KCLJ0REREQkv1DFTkRERIKEKnYiIiIikk+oYiciIiLBQefYiYiIiEh+oYqdiIiIBAlV7EREREQkn1DFTkRERIJDEJxjp45dEFj03W8M/3gxKSkpdG91EQ90uSzd8hnLfuLdWd8CULxIIQbe3Zq6VaJSl3tSUugxeBLR4SV4+7Eufs39z3LOMezVMcQtXUXRokUYMaAP9evUzBS34/fd9BnwPAcOHuaiOjV4YeCTFC5U6Izr/7JtB30GPJ+6/vadu3jkgbu459br/di687Poxz0M/+InUlIc3ZtU5IE2VdMtn7spkdfn/EKIQWiI8XTX2lxetSwnTnm4a+y3nExOITnF0eniaB7uUD0wjfiTFm3YyvAJC7zHfpuLeeDapumWz1iymXdnrgZ8x/697ah7YTl27TlEvzFfkXTgKGZwc9sG3N3psixeIW9btOYHhr87jRRPCt07NuOB7rHplv+yI4F/jfyUTT/v4LG7ruG+G9qkLmt3/zBKFCtCaEgIoaEhTPr3Y37NPScs2rCV4RPjvMd+6/o80LVxuuUzlv7AuzPXAFC8aCEG3tOWulXKceJkMncNn8zJZA/JnhQ6NanJwzdeEYgm5Jpuw96hdpvOHNmTwOjrGgU6HclB6tgVcJ6UFIZOiOO9J68lJqIkNw+ZRNuGVal5QURqTKWoUozvdz1lShQlbsM2Bo5bwKcDuqcunzBnA9UrhHP4+MlANOFPiVu2mm3bdzL7s3dZv/FHBr84iv++91qmuJfffJ97br2BLh1aM/CFN5g842tuu7HLGdevfmElpo4fBYDH46H1dXfTvvWVfm5d9nlSHEOn/8h7PRsRU7oIN7+5irb1oqgZUzI15ooa4cTWa4qZ8eOuQzz+n++Z1edKCoeF8MH9jShRJIxTnhTufHsNLetE0rBKmQC2KPs8KSkMHTeP9/55IzERpbj52Y9pe1kNal4QmRpTqVwZxvfv4T321//KwPe/4dPBtxEaajx1eyvqV43hyLGT3PTsRJpffGG6dfM6jyeFoWOm8N6QXsREluHmJ0bStulF1KxSPjWmTMli9O/VjbnLN2a5jXHDHiK8dAl/pZyjPCkpDB2/gPeeusH73TfoU9o2qpZ5///rJt/+38rAD+bx6cBbKFwolA/63UCJooU5lezhzmGTaHnJhTSsWSGALcpZ66aMY+XE0dzw/PuBTsXPCn7FLtfPsTOzpbn9GrnNzKqa2TEzW+d7vJ1m2eVm9p2ZbTGz1828dV4zG2RmT/qeFzWzOWY20N+5b/glgSrRZagcXYbCYaF0blqTeWt/TRfTqFYFypQoCsClNWLYvfdI6rLdew+zcP02ureq59e8/6q5ccvpdk07zIyGF9fl4OEjJCTtTRfjnGP5mg10atsCgOs7t+ebuGXZXn/Z6vVUvqA8F1SI8U+j/oQN2w9SJbIYlSOKUTgshM6XxjBvc1K6mBJFwvAdthw9mZL6tWdmlCji/dsv2eM4leLy1Vfihp93UyWmLJWjy3qP/SvqMG/Nz+liGtWuePrYr1mB3fsOARBdtiT1q3r3a4lihalRMYL4vYf924C/aMP/fqNKhUgql4+kcKEwOrdsyLwV6TtwkWVL0aBWFcJCC97p1ht+ifftf993X7NazPv2l3Qx6b77apZnt28fmxklihYGINmTwilPSupnpKDYtnoxxw7sPXeg5Cozu9rMfvT1Ifplsdx8fYstZrbBzM45dJDrFTvnXPPcfo2/yszCnXP7zhH2s3OuYRbz3wJ6AcuBWcDVwJdptl0YmAyscc4NzpmMsy9h3xHKR5yuzsRElGTDz/FnjJ8ct5mWDaqkTo/4z2KevPlKjhw/lat55rT4xCQqxJRLnS5fLor4xCSio05XKvcfOEjpkiUICwv1xkRHkZC4J9vrz5qzkC4d2uRyS/6ahIPHKV+maOp0TOkibNh+MFPcnI0JvDr7Z/YePslb9zRMne9JcXQftZLf9hzjtisqcWk+qdYBJOw7TPmIUqnT3mN/9xnjJy/4npaXVMs0f2fiATZvS+TSmuWzWCvvSthzgPJRZVOnY6LKsuHHbdle34Cez47FDG7pdCU3X52/hiK9+/88vvsWbqLlJRemTntSUug+8BN+iz/Abe0u4dIa+Wv/yxnkoQ66mYUCbwIdgB3AKjOb7pzblCbsGqCW79EMb5+j2dm264+K3WHfv23MbIGZTTKzH8xsYprqVhMzW2pm681spZmV8lW5PvBVw9aaWVtf7L1mNtXMZpjZr2bW28z6+GKWm1mEL66GmX1lZmvMbJGZ1T1LmreY2fdm9qSZlTtLXMa2VQBKO+eWOeccMB64Pk1IGPAJ8D/nXKaeuG8bvcxstZmtHjst54ubDpfVa2YZu2LzTiYv2swTN3uHFuev20pEqWLUrxqd43kFQsZ2u8xvTbbXP3nqFPMWr+Dqdi1yIrVck1UTs9r9HepHM6vPlbxx1yW8Pud0VSs0xJjySDPm97uK73Yc4Kfd+adqldX+PeOxv2k7k+M28sQt6ffnkeMneeT1L+h3R2tKFiuSG2nmmvNpf1Y+fqE3n7/2OGMH3s/Hs5aw6vufz71SHpJ1+7OOXbH5j/1/Veq80JAQpgy9nfmv3sd3v+zmpx17cilTCWJNgS3OuV+ccyfx9he6ZYjpBox3XsuBsr6+xxn5u/7eCHgMuAioDlzlq2h9CjzqnLsUaA8cA/4B4JxrANwGjDOzP0oPFwO3431ThgFHnXONgGXA3b6YscDDzrnLgSeB0WdKyjn3Nt5ecTEgztf5vNrM0r4/1Xydx4Vm1tI37wK8vew/7PDN+8NTQLJz7rGzvPZY51xj51zjXt1yvrgZE14ydXgBIH7vYaLLFs8U9+P2JAZ8MJ9Rj3QmvKT3bV77v13MX7eVdk9O4Im3vmbF5p08NWZOjueYUyZOmsH1d/fm+rt7Ex0Vwa74xNRluxOTiI5Kf35UeNnSHDx8hORkjzcmIYnoct6YmHJRZ11/0bLVXFSnBlER4bnZpL8spnRRdh84njodf/AE0aXP3EFpUi2c7XuPse9I+vMpSxcrRNNq4Sz+Kf/8uMVElGT33kOp095jP/P5Yj/+lsiA9+Yw6rHrCC9VLHX+qWQPj77+Bdc2r0vHJrX8knNOiokqw+6k/anT8Un7iY4one31oyO91dnIsqVof8XFfPe/7TmdYq7y7v+M331Z7f8kBrw3l1GPdSW8ZLFMy0uXKELTupVYvCH71U7Jy8xvj7SFG9+jV4ZkLgDSfrAy9iGyG5OOvzt2K51zO5xzKcA6oCpQB9jlnFsF4Jw76JxLBloAE3zzfgC2AbV925nvnDvknEsEDgAzfPO/A6qaWUmgOfCZma0DxgBn7eE657Y754bi7XS+53tM9S3eBVTxdR77AB+bWWmyPgsz7d+Ji4Erzax2FnF+0aBaNNsSDrAj8SAnkz3MWrmFto3SDzf9vucQj4z6ihceaEe18mVT5/fpcSUL/n0Pc1++i1ce6kizehfw4t87+LkF2XdH92uZOn4UU8ePol2rK5n25Vycc6z7/gdKlSiRbhgVvNWLZpddwuz5iwGYOusb2rX0DjfFtmx21vVnzllIlw6t/de4P6lBpVJsSzrKjr3HOJmcwqz18bStF5UuZlvSUZyvvLFx50FOeRxlixdi7+GTHDzmHYI/fsrDsp/3Uq1c/jmRvkH18mzbvY8dCQe8x/7yH2l7Wfqren9POsgjI2fwwt+vplqF05105xzPvDuH6hUjuPeay/2deo5oUKsy235PYsfuPZw8lcysReto26x+ttY9evwER44eT32+ZN1P1KqSv4YiG1SLYVv8fnYk+vb/iv/RtlGG/b/nEI+8MZMX/t6JauVP7/+9B49y8MgJAI6fTGbZpu1Uq5i3/4iTvCdt4cb3GJsh5Fx9iOzGpOPvq2JPpHnu8b2+cYYRo2xuJyXNdIpvmyHA/jOcE3dGZtYU+Bve8e7PgHcAnHMn/ngN59waM/sZbydzB1ApzSYqAb+nmY4DxgFfmllL51zaZX4RFhrCM3e05P5XZpCS4rixZV1qXRDBJ/O/B+DWthczetpq9h8+wZAJcQDeWxsM7OHvVHNU6+ZNiFu6io49elK0SBGGP/N46rJefZ5l6NOPElMukif/8Tf6DHiBkWPGU692Dbpf2+mc6x87fpwlK9cy+J8P+71d5yssNIRnrqvD/e+vJcXBjY0rUCumJJ+s8Baab21Wia83JjDt290UCjWKhIXw79suxsxIPHSCpz/bhMdBinNc3SA6U6cwLwsLDeGZu2O5/6XPvcd+q/rUqhTFJ3PXA3Bru0sZPXUF+w8fZ8i4eQCEhhqThtzBtz/9zvQlm6ldOYob+n8EwGM9rqJ1w8zn4OVVYaGhPPP3G7h/0Dve9rdvQq0q5fnkS+8pH7de05zEfQfp0Wckh48eJyTEGD99EV+82Zd9B4/w8PAPAe/FA11bN6Ll5Wc7myXvCQsN4Zm72nD/S9NISUnx7f9IPpn3HQC3xjY4vf/Hzwe8w6+TBt9K4v6jPP3O13hSnPfYb1qLtvlo32fHTa9MoGqT1hQPj6LPgl+Z/8YQ1k7+INBpBZsdQOU00xn7ENmNScfc+Z5odJ7M7LBzrqSZtQGedM519c0fBawGPgZ+AG5xzq0ys1J4h2IfAeo753r6Kl5z8HambgMaO+d6+7az1TedZGb3/rHMdzXuq865z3zn8l3inFt/hhw7Ai8Du/FW6qb4xrv/WF4O2Ouc85hZdWAR0MA5t9fMVgEPAyvwXjzxhnNulpkNAg475142sweB/wNaOef2n+m9Slk6Mnd3Rh5mdbsGOoWAcgteCXQKgVXpkkBnEDhlzjqqUvDt+y3QGQTUkHsfC3QKATXoh1N+vZrB7f3Zb7+zFlHjrG0zszDgJ6AdsBNYBdzunNuYJqYL0BvojPeiidedc02z2FyqgN/Hzjl30sxuAd4ws2J4O3Xt8Z4T97aZfQckA/c6506cx8m/dwBvmdkzQCG8JyVm2bED9gDXOufOdBJFK2CImSXjrTQ+6Jz74zrxh4AP8Z6f9yVprohN08a3zaw8MN3MOjrnjmeMERERkeDhnEs2s97AbCAUeN85t9FXDPrj/P9ZeDt1W4CjeEcVzyrXK3aSfarYBS9V7FSxC1qq2AU6hYDyd8WOfb/473c2vHpA7q1S8O5KKSIiIhKkAj4U609m1h/IeFXAZ865YYHIR0RERPwp79ygOLcEVcfO14FTJ05EREQKpKDq2ImIiEgQy0P/pVhu0Tl2IiIiIgWEKnYiIiISJFSxExEREZF8QhU7ERERCQ46x05ERERE8gtV7ERERCRIqGInIiIiIvmEKnYiIiISHHSOnYiIiIjkF+rYiYiIiBQQGooVERGRIKGhWBERERHJJ1SxExERkeCgiydEREREJL9QxU5ERESChCp2IiIiIpJPqGInIiIiwaHgF+xUsRMREREpKFSxExERkSBR8Et2qtiJiIiIFBCq2ImIiEhw0H3sRERERCS/UMVOREREgoQqdiIiIiKST6hiJyIiIsFB59iJiIiISH6hjp2IiIhIAaGhWBEREQkSBX8o1pxzgc5B8ggz6+WcGxvoPAIhmNsOar/ar/YHa/uDue0FlYZiJa1egU4ggIK57aD2q/3BLZjbH8xtL5DUsRMREREpINSxExERESkg1LGTtIL5PItgbjuo/Wp/cAvm9gdz2wskXTwhIiIiUkCoYiciIiJSQKhjJyIiIlJAqGMnIiIiUkCoYyeYWYlA5xAIZlYkO/NECjIzCzGz0oHOw5/O8NmPCEQueYmZFQ50DvLXqWMXxMysuZltAjb7pi81s9EBTsuflmVzXoFkZo3NbIqZfWtmG8zsOzPbEOi8/MnMQs2soplV+eMR6Jz8wcw+NrPSvj/qNgE/mlnfQOflR5+bWaE/JsysAjAngPn4jZkNOMP8MsDXfk5HcoH+r9jg9irQCZgO4Jxbb2atAptS7jOz8sAFQDEza8Tp/zywNFA8YIn530SgL/AdkBLgXPzOzB4GBgLxnG6/Ay4JWFL+c5Fz7qCZ3QHMAv4JrAFeCmxafjMV+MzMbgIq4/0OfDKgGflPSzMb5pzr/8cM33fibGBy4NKSnKKOXZBzzm03S/efInsClYsfdQLuBSoB/04z/xDwr0AkFCCJzrnpgU4igB4F6jjn9gQ6kQAo5KtYXQ+Mcs6dMrOgufeVc+4d37DjVKAq8Hfn3NKAJuU/1wGTzOzfzrk+ZlYL+BJ4yTn3/+3de9CVZb3G8e8FKqCCkqVZpqaphGcQ0zJMO5hlnlDbOysnq70z2+rWrM1MW83SGieztC1ZkiGdPeV2agxD5ZCaAqJYaGVmarrLBEINRb32H/e9ZPH6gk2s97nluX+fmTW8z7NYM9fi8L73ug+/30WFs4UeiIFd3R6Q9EbA+ZvcCeRl2TazPQWYImmC7Zo/oZ4u6WJgOvBU56btK8tFatQDwJLSIQq5CPgDcAcwU9JWwN+KJmqApJO7L0mzdfOBvSTtZfvL/b6wRWwvk3QY8ANJPwD2Bk6yfVXhaKFHokBxxSS9HPgq8DbSN7lpwIm1zGD0+SbfsQSYa3t+w3EaJ+k7wCjgV3QtRdo+tlyq5kiaDOwA/ISVB7at/+HeH0nr2H6mdI6BJOn01T1v+7NNZSml6/veusCngFnAzM7ztf77b5OYsauY7UeBo0vnKGiP/LgmX78buA34mKTLbJ9TLFkzdrW9c+kQBf0xP9bLj2pIOhG4hLT94GJgd+C/aPnm+b4DN0kb2H6iVJ5Chnd9fX4/98JaLmbsKibp/H5uLwHm2L666TxNk/QzYILtx/P1hsDlwGGkWbvRJfMNNEnfBM6z/evSWUKzJN1he1dJBwDHA/8NXGJ7TOFojZC0NzAZ2ND2lpJ2Je2z+3jhaCGssZixq9tQ0lLcZfl6AmlZ7sOS9rN9UqlgDdkSeLrrejmwle2/S3pqFa9pk32AYyTdR1qKFGkpttWnQiV9xfZJkq4hnYJdie2DC8RqWufE1LtIA7o71OcUVct9hQorAnTkAf2hpOoABv4EXG372pK5Qm/EwK5urwP27+yrkTSJtBTzdlIJjLb7HnCLpM7s5HuA73fV9mq7d5YOUMjU/OuXiqYoa66kacBrgYmShlNZyZtKKwIg6SvA9sClwIP59hbACZIOtH1iqWyhN2IptmKS7gH2tL0kX28E/NL2KEm32969bMKBJ2ksaeZKwGzbcwpHasyqivHa/mPTWUKzJA0CdgN+b3uxpE2AV9uuokC1pMtJpY6+BuxFqgiwh+1/KRqsAZJ+Y3v7fu4L+I3t7QrECj0UM3Z1OweYL+lG0sBmPHB2nrH6eclgTZB0JulE2MUVbqCGdBrUpL/7oaTZm3uAHUuGakqu3/UFYDTp/QNge5tioRpi+zlJWwDvy7NWM2xf8yIva5OPkSoCvJo0azWNtNewBssk7Wn71j73xwHLSgQKvRUzdpWT9CrgA8DdwAbAg7Znrv5V7SDpWNJs3d6k04GzgJk1HBzpj6QxpA3k/146SxMkzSZ1njiPtAz/IdL3xNWWxGgDSV8k/SD/br71r6RDUxPLpQpNyP/PJ5FOwnaWYl9DqmP4cdtzS2ULvREDu4pJ+gip+v4W5CKdwM229y+Zq2m5nc5RpJZCI21Xe/Rf0ryKTkbOtT1W0oJO2RdJs2y/uXS2gZZ7Au9m+7l8PRi4ve0HZzokbU8a3GxmeydJuwAH2/584WiN6WqtKNIH+kcKRwo9EkuxdTuR9Kn9Ftv7SRoFtL5AZ0fuujCa1Ct0FnAEMK9oqAb1KdA8CBgD/KVQnBKW5b1mv5X0CeAhYNPCmZq0MfBY/nqjgjlK+CapT/JFALbvlPQ9oJqBXR7IPZLLPG0vaZntxYVjhR4YVDpAKGqZ7WUAkobYvptUib8WmwCDgcWkH3CPtr3yfh/Dux5DSHvuDimaqFknAeuTNs6PJW1JOKZkoAZ9Abhd0rclTQHmAmcXztSk9fvZY1bF/31JF3Z9vQ+pAsC5wAJJ7yoWLPRMzNjV7UFJG5MaYV8naRGpnlEVbB8GIOn1pJpWN0gabHuLssmaUUP7pNWxfVv+8nHS/rpq2P5+PjQ1jrQU9+nKluIelbQtuY6hpCOAh8tGasxeXV9/DjjU9jxJ2wA/An5aJlboldhjFwCQtC9pOeZa20+/2O9vA0kHAW8mnQYeCdwMzLL9raLBGpL3GX0S2JquD3m17LFcRYHiJcAc4KLObHab5I3zq2S7iq0IeRDzDeCNwCLgPuBo2/cXDdaA7n20nX2mXc9VUeaq7WJgF6ol6X9Iza9n2a5mprJD0h3A10nLcM8XZ63lVJykrwKvAL6fb70XeAQYBoyw/YFS2QaKpBtW87RrGdR35NJOg2wvLZ2lKZKeBH5HmqndGtjS9qK83/RO2zuVzBfWXAzsQqhU30/rtZE00/b4/u5J+pXtKur51UjSvcAtrChxVEOnGQAkbdXn1sO2n5b0cmC87StL5Aq9EwO7UB1JS+mnRygreqWOaDhSEZLOAP4MXEXqFQuA7cdW9Zo2kbQQOKDTaSN34rjW9uialqQkfcP2v5XO0SRJQ4A3kLZivInUM/uOzr7bENZmcXgiVKfmOnV9dE6Antp1z0DrOy9kpwCz8+yNSJ03Pp6X56YUTdasPUoHKOBZYHn+9TlSyaM/F01UQG4jdhUw0fbC0nlCb8SMXahaLsy6GSsfHoheqZXIMzejSAO7u9t4YOLFSLrW9jtL52hS3me2gNQv9ue2/1o4UhGSDgAmAz+0fUrpPKE3YmAXqiXpP0gtpf6P9Kkd0lJsFdX3u9W4HNet9vdfG0mHkNoJ7gk8DdxE2ms3vWiwhkn6EfAt4HxgdGV1PFsrBnahWpJ+B7yh1k/r3WpqJdafWt7/Kkq8PM/2wQ3GKS532zmQVKx6U9vDyiZqTj4sMcP2jrlo8Q22LyudK6y52GMXavYAqW5ZqHB/UR+1vP8vlQ7wUiDpCmA3UtmP2cAHgV+WzFTAB1lR6ucSUrHiGNi1QMzYhWpJmkxqofYTVj4V+uVioUIIA07SOGCe7Wdf9De3lKQFwDttP5Sv7wAOsv1A2WRhTcWMXaiOpKm5+OwE4DxgvfyoQu3LcbW/fwBJ25H6xY4Ghnbu267iRHRXO7kq91fmVpJf6wzqsk8CLyetZIS1WAzsQo3G5iKdfwQuKB2mgNqX42p//5CW3k4nfbDZj9QrV0UTlVNduRfbi4GL+ty7rvta0kTbX2gyV+iNWIoN1ZF0AnAcqW5ZdyuxToHiKmYtQr06XUckLbC9c743y/abS2cbaLl11l62b8rX1ZV7+UfUcqCojWJgF6olaZLt40rnKKX25bia37+kX5C6LlwOXA88BHzR9g5FgzVE0s229y6d46Wspu4rbTOodIAQSql5UJddAkwCniEtx10KTC2aqFk1v/+TgPWBE4CxwPtJpyRrMU3ShNx5IfQvZn3WUjGwC6Few3JBVtm+3/YZwP6FMzWp5ve/te3HbT9o+0O2JwBblg7VoJNJpT2elvQ3SUsl/a10qJeYGPSupeLwRAj1Wpb3G/1W0idIy3GbFs7UpJrf/0ReWLOsv3utFP2i/yFV/Ftoo9hjF0Klci2vhcDGpOKkGwHn2L6lZK6m9PP+R5Def2sL1Uo6EHgXcBTww66nRpBaSu1ZJFjD8hLs0cBrbX9O0muAzW3fWjhaYyRtT9qKsJntnSTtAhxs+/OFo4U1FAO7EEKVJB3Zt4VSf/faRNKupI4LZwKndT21lNRSalGJXE2TNInUH3p/26+XNBKYZntc4WiNkTQDOBW4qHNIQtJdtncqmyysqRjYhVCp/In9VGArurZl2K5in1l/5RxqKfEgaZ2aG753/p67T35KusP2rqWzNUXSbbbH9fkzmG97t8LRwhqKPXYh1Osy4OvAN4FqWit1LUe+WtL5XU+NIJ2QbS1JP7J9FHC7pBd8qre9S4FYJSyXNJh88lPSK0gzeDV5VNK2rPgzOAJ4uGyk0AsxsAuhXs/YnlQ6RAF/AuYABwNzu+4vBf6zSKLmnJh/PahoivLOB64CNpN0FnAE8JmykRp3PPANYJSkh4D7SGVvwloulmJDqJSkM4A/k37APdW5b/uxUpmaFMuReiWwJ2nG5jbbjxSO1ChJo4C35svrbS8smacUSRsAg2wvLZ0l9EYM7EKolKT7+rnd+pZqneVISQvopwhrDcuRkj5COjxxPale2b7Amba/VTRYgySNAfYh/Rv4he15hSM1StLGpKLUW7PyHtsTCkUKPRIDuxBCVSRtbvthSVv197zt+5vO1DRJ9wBvtP3XfL0JcFNFLcVOA44EriANbA8FLqup1Iekm4BbgAV07S+0PaVYqNATMbALoVKS1gWOA8bnWzeSSh8sLxaqYbUuR0qaDhxo++l8vR7wU9tvK5usGZIWArvbXpavhwHzbL++bLLm1HICvEbRUiyEek0i9Qm9MD/G5ntVyMuRtwKHkzbP3yLp2LKpGvMQ8EtJZ0g6nTRz8ztJJ0s6uXC2JvwBGNp1PQS4t0yUYqZK+qikzSW9rPMoHSqsuZixC6FS/dXtqqmWV83LkXkwt0q2P9tUlhIk/RgYB1xHmq19OzCbdJioin1mko4HzgIWs2Kvaev32NYgyp2EUK9nJW1r+14ASdtQUT074EFSiZOOpcADhbI0qu0Dt3/AVfnRcWOhHCWdDLzO9qOlg4TeioFdCPU6FbhB0u9JG8i3Aj5UNlKjOsuRV5NmLA4Bbu0sRdr+cslwAykX5P0UsCNdS5K1dB3pPiAgaUxtJ2KzXwFPlg4Rei8GdiFUyvZ0SdsBO5AGdnfbfupFXtYm97Lyvqqr86/DC2Rp2neBH5IKFX8MOAb4S9FE5VwM1HiI4FlgvqQbWLmOZeuXodsu9tiFUBlJ+9u+XtLh/T1v+8qmM4VmSZpre6ykOzt1+yTNsL1v6WxN6+6VWhNJx/R3P8qdrP1ixi6E+uxLKkz7nn6eM1DFwK7y5chOSZuHJb2b1GZti4J5Sqpyv6HtKbnMzfb51j01lTpqs5ixC6FSkl5r+74Xu9dWkqaRliM/SddypO1PFw3WAEkHAbOA1wAXACOAM2xfUzRYQyS9CZhv+wlJ7yctxX61huLUHZLeAkwhlX4R6d/CMbZnlksVeiHq2IVQryv6uXd54ynK2cT2ZGC57Rm2jwX2Kh2qIUeSPtjfZXs/UrmPwwpnatIk4ElJu5IOEd0PXFo2UuPOBd5he1/b44EDgPMKZwo9EEuxIVQmNz/fEdiozz67EaxctLXtal6O3MX24s6F7cck1bTP7BnblnQIcL7tyavac9Zi69q+p3Nh+ze5G01Yy8XALoT67EA6DbkxK++zWwp8tESgQj4vaSPgFFYsR55UNFFzBkkaaXsRQO44UNPPg6WSJgLvB8ZLGgzUNqiZI2kyMDVfHw3MLZgn9EjssQuhUpL2tn1z6RylSJoCnNiZucqDmy/lJdlWk/RBYCJp6d3AUcBZtqeu9oUtkXsEv4/UH3iWpC2Bt9iuZjlW0hDgeGAf0h67mcCFlZU8aqUY2IVQKUlDgQ/zwlOhrR/YQP9lLmoqfSFpNLA/6Yf6dNu/LhypEXl27me231Y6S0mSNgCW2X42Xw8GhtiOosVruTg8EUK9pgKvJG2ankHaX7Z0ta9ol0GSRnYualuOtP1r21+zfUEtgzqAPJB5Mi/D12w6MKzrehjw80JZQg9V800shPACr7N9pKRDck2r7wE/Kx2qQecCN0laaTmybKTQkGXAAknXAU90blbWdWGo7cc7F7Yfl7R+yUChN2JgF0K9OqdCF0vaCXgE2LpcnGbZvlTSHFYsRx5e08xV5X6SHzV7ortPrqSxwN8LZwo9EHvsQqiUpI+QatntDHwb2BA4zfbXS+YKIQw8SeOAH5DK/ABsDrzXdpyMXcvFwC6EEEJVJN1HWn5fie1tCsQpJtet24E0Y313tBRrh1iKDaFSks4Gzukq9zESOMX2Z4oGC2Hg7dH19VBSJ46XFcpS0jjS9ot1gN0lUVPJl7aKGbsQKrWKch/zbI8plSmEUiTNtr1P6RxNkTQV2BaYDzybb7uyAyStFDN2IdRrsKQhnYKkkoYBQwpnCmHASer+8DKINIM3vFCcUvYARjtmd1onBnYh1Os7wHRJl5D2Gx0LTCkbKYRGnNv19TPAH0jlbmpyF6mO5cOlg4TeiqXYECom6UDgraTN09Ns11THLoRqSboB2A24FXi+jZjtg0tlCr0RA7sQQghVyV0nTgfG51szgDNtLymXqlmS9u3vvu0ZTWcJvRUDuxAqJWkpK0o+rAesCzxhe0S5VCEMPElXkJYiO1sPPgDsavvwcqlC6I3YYxdCpWyvtFlc0qHAnmXShNCobW1P6Lr+rKT5pcI0qXP6t88HO0jbMRwf7NZ+g0oHCCG8NNj+Mam9Vght93dJz5c2kfQmKmmn1SnpYnu47RFdj+ExqGuHmLELoVKSupedOiUfYm9GqMFxwJS81w5gEXBMwTwh9EwM7EKo13u6vu6UfDikTJQQGrUQOIdUoHdjYAlwKHBnuUgh9EYcngghhFAVSdcCi4F5rOi6gO1zV/WaENYWMbALoTKSLmA1S67RUii0naS7bO9UOkcIAyEOT4RQnznAXFLz8zHAb/NjN7pmL0JosZsk7Vw6RAgDIWbsQqhUrjz/DtvL8/W6pO4T+5VNFsLAkLSANFu9DrAd8HtS14VOqY9dCsYLoSfi8EQI9XoVqfH5Y/l6w3wvhLY6qHSAEAZaDOxCqNcXgXmSbszX+wJnFEsTwgCzfX/pDCEMtNhjF0K9vg2cBuwCXEka2C0sGSiEEMKaiRm7EOp1IfAcMMz2/0oaCVwBjCsbK4QQwj8rBnYh1OsNtsdIuh3A9iJJ65UOFUII4Z8XS7Eh1Gu5pMHkmnaSXkGawQshhLCWioFdCPU6H7gK2FTSWcBs4OyykUIIIayJqGMXQsUkjQLeSqrjNd12HJ4IIYS1WAzsQgghhBBaIpZiQwghhBBaIgZ2IYQQQggtEQO7EEIIIYSWiIFdCCGEEEJLxMAuhBBCCKEl/h9P+5x9XuxEqAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(data=df.corr(), annot=True, cmap= 'Oranges')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3dd010c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the fnlwgt colummn\n",
    "\n",
    "df.drop('fnlwgt', axis=1, inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4f36075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income_&gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>16</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>99999</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>Private</td>\n",
       "      <td>12th</td>\n",
       "      <td>8</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  education  educational-num marital-status       occupation  \\\n",
       "0   67   Private  Doctorate               16       Divorced  Exec-managerial   \n",
       "1   17   Private       12th                8  Never-married    Other-service   \n",
       "\n",
       "    relationship   race gender  capital-gain  capital-loss  hours-per-week  \\\n",
       "0  Not-in-family  White   Male         99999             0              60   \n",
       "1      Own-child  White   Male             0             0              15   \n",
       "\n",
       "   income_>50K  \n",
       "0            1  \n",
       "1            0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "035f7f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43791, 13)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9363e092",
   "metadata": {},
   "source": [
    "### 5) Dealing with the categorical values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4425226",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the list of categorical type features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b26b15ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 43791 entries, 0 to 43956\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   age              43791 non-null  int64 \n",
      " 1   workclass        43791 non-null  object\n",
      " 2   education        43791 non-null  object\n",
      " 3   educational-num  43791 non-null  int64 \n",
      " 4   marital-status   43791 non-null  object\n",
      " 5   occupation       43791 non-null  object\n",
      " 6   relationship     43791 non-null  object\n",
      " 7   race             43791 non-null  object\n",
      " 8   gender           43791 non-null  object\n",
      " 9   capital-gain     43791 non-null  int64 \n",
      " 10  capital-loss     43791 non-null  int64 \n",
      " 11  hours-per-week   43791 non-null  int64 \n",
      " 12  income_>50K      43791 non-null  int64 \n",
      "dtypes: int64(6), object(7)\n",
      "memory usage: 4.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09bd33fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_values= list(df.select_dtypes(include='object').columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "002ba9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['workclass',\n",
       " 'education',\n",
       " 'marital-status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'gender']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d377c15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.get_dummies(data=df, columns=categorical_values, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0033ea55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43791, 59)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48b2cf2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income_&gt;50K</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Never-worked</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>...</th>\n",
       "      <th>relationship_Not-in-family</th>\n",
       "      <th>relationship_Other-relative</th>\n",
       "      <th>relationship_Own-child</th>\n",
       "      <th>relationship_Unmarried</th>\n",
       "      <th>relationship_Wife</th>\n",
       "      <th>race_Asian-Pac-Islander</th>\n",
       "      <th>race_Black</th>\n",
       "      <th>race_Other</th>\n",
       "      <th>race_White</th>\n",
       "      <th>gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>16</td>\n",
       "      <td>99999</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  educational-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0   67               16         99999             0              60   \n",
       "1   17                8             0             0              15   \n",
       "\n",
       "   income_>50K  workclass_Federal-gov  workclass_Local-gov  \\\n",
       "0            1                      0                    0   \n",
       "1            0                      0                    0   \n",
       "\n",
       "   workclass_Never-worked  workclass_Private  ...  relationship_Not-in-family  \\\n",
       "0                       0                  1  ...                           1   \n",
       "1                       0                  1  ...                           0   \n",
       "\n",
       "   relationship_Other-relative  relationship_Own-child  \\\n",
       "0                            0                       0   \n",
       "1                            0                       1   \n",
       "\n",
       "   relationship_Unmarried  relationship_Wife  race_Asian-Pac-Islander  \\\n",
       "0                       0                  0                        0   \n",
       "1                       0                  0                        0   \n",
       "\n",
       "   race_Black  race_Other  race_White  gender_Male  \n",
       "0           0           0           1            1  \n",
       "1           0           0           1            1  \n",
       "\n",
       "[2 rows x 59 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be26f520",
   "metadata": {},
   "source": [
    "#Note: The error I was facing was because the dataframe had changed when I had executed the line earlier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89923e75",
   "metadata": {},
   "source": [
    "# 3) Train Test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50d0f8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('income_>50K', axis=1)\n",
    "y=df['income_>50K']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95269d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43791, 58)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6896a872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43791,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63af3d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size=.25, random_state=52)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d232d934",
   "metadata": {},
   "source": [
    "# 4) Standardization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c7ec5958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "SC= StandardScaler()\n",
    "\n",
    "X_train=SC.fit_transform(X_train)\n",
    "X_test=SC.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f77ce1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f477f18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We do not do scaling on the target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689e3d79",
   "metadata": {},
   "source": [
    "# 5) Training different models and comparing their performances "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d065bc01",
   "metadata": {},
   "source": [
    "We will use follwing different algorithms :\n",
    "    \n",
    "    1) KNN Classifier\n",
    "    \n",
    "    2) Random Forest Classifier\n",
    "    \n",
    "    3) Decision Tree \n",
    "    \n",
    "    4) Logistic Regression \n",
    "    \n",
    "    5) XGBoost "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50caf3c3",
   "metadata": {},
   "source": [
    "We will search for the best parameters for the above algorithms using randomizedsearchcv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45837578",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the library for Randomized Search CV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#Importing library for metrics for model evaluation \n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "#Make a dataframe to store the accuracy data of all the models for easy comparision \n",
    "result=pd.DataFrame(columns=['Model','Accuracy Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb50579",
   "metadata": {},
   "source": [
    "### 1) KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "20f78dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV 1/3; 1/10] START algorithm=auto, leaf_size=14, metric=minkowski, n_neighbors=14, p=2, weights=distane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 206, in predict\n",
      "    weights = _get_weights(neigh_dist, self.weights)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 111, in _get_weights\n",
      "    raise ValueError(\"weights not recognized: should be 'uniform', \"\n",
      "ValueError: weights not recognized: should be 'uniform', 'distance', or a callable function\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 1/10] END algorithm=auto, leaf_size=14, metric=minkowski, n_neighbors=14, p=2, weights=distane; total time=   8.1s\n",
      "[CV 2/3; 1/10] START algorithm=auto, leaf_size=14, metric=minkowski, n_neighbors=14, p=2, weights=distane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 206, in predict\n",
      "    weights = _get_weights(neigh_dist, self.weights)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 111, in _get_weights\n",
      "    raise ValueError(\"weights not recognized: should be 'uniform', \"\n",
      "ValueError: weights not recognized: should be 'uniform', 'distance', or a callable function\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 1/10] END algorithm=auto, leaf_size=14, metric=minkowski, n_neighbors=14, p=2, weights=distane; total time=   4.9s\n",
      "[CV 3/3; 1/10] START algorithm=auto, leaf_size=14, metric=minkowski, n_neighbors=14, p=2, weights=distane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 206, in predict\n",
      "    weights = _get_weights(neigh_dist, self.weights)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 111, in _get_weights\n",
      "    raise ValueError(\"weights not recognized: should be 'uniform', \"\n",
      "ValueError: weights not recognized: should be 'uniform', 'distance', or a callable function\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 1/10] END algorithm=auto, leaf_size=14, metric=minkowski, n_neighbors=14, p=2, weights=distane; total time=   4.8s\n",
      "[CV 1/3; 2/10] START algorithm=auto, leaf_size=5, metric=minkowski, n_neighbors=13, p=2, weights=uniform\n",
      "[CV 1/3; 2/10] END algorithm=auto, leaf_size=5, metric=minkowski, n_neighbors=13, p=2, weights=uniform; total time=   5.2s\n",
      "[CV 2/3; 2/10] START algorithm=auto, leaf_size=5, metric=minkowski, n_neighbors=13, p=2, weights=uniform\n",
      "[CV 2/3; 2/10] END algorithm=auto, leaf_size=5, metric=minkowski, n_neighbors=13, p=2, weights=uniform; total time=   4.9s\n",
      "[CV 3/3; 2/10] START algorithm=auto, leaf_size=5, metric=minkowski, n_neighbors=13, p=2, weights=uniform\n",
      "[CV 3/3; 2/10] END algorithm=auto, leaf_size=5, metric=minkowski, n_neighbors=13, p=2, weights=uniform; total time=   4.6s\n",
      "[CV 1/3; 3/10] START algorithm=auto, leaf_size=8, metric=minkowski, n_neighbors=17, p=2, weights=distane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 206, in predict\n",
      "    weights = _get_weights(neigh_dist, self.weights)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 111, in _get_weights\n",
      "    raise ValueError(\"weights not recognized: should be 'uniform', \"\n",
      "ValueError: weights not recognized: should be 'uniform', 'distance', or a callable function\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 3/10] END algorithm=auto, leaf_size=8, metric=minkowski, n_neighbors=17, p=2, weights=distane; total time=   4.9s\n",
      "[CV 2/3; 3/10] START algorithm=auto, leaf_size=8, metric=minkowski, n_neighbors=17, p=2, weights=distane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 206, in predict\n",
      "    weights = _get_weights(neigh_dist, self.weights)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 111, in _get_weights\n",
      "    raise ValueError(\"weights not recognized: should be 'uniform', \"\n",
      "ValueError: weights not recognized: should be 'uniform', 'distance', or a callable function\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 3/10] END algorithm=auto, leaf_size=8, metric=minkowski, n_neighbors=17, p=2, weights=distane; total time=   5.0s\n",
      "[CV 3/3; 3/10] START algorithm=auto, leaf_size=8, metric=minkowski, n_neighbors=17, p=2, weights=distane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 206, in predict\n",
      "    weights = _get_weights(neigh_dist, self.weights)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 111, in _get_weights\n",
      "    raise ValueError(\"weights not recognized: should be 'uniform', \"\n",
      "ValueError: weights not recognized: should be 'uniform', 'distance', or a callable function\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 3/10] END algorithm=auto, leaf_size=8, metric=minkowski, n_neighbors=17, p=2, weights=distane; total time=   4.7s\n",
      "[CV 1/3; 4/10] START algorithm=auto, leaf_size=13, metric=minkowski, n_neighbors=8, p=1, weights=distane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 206, in predict\n",
      "    weights = _get_weights(neigh_dist, self.weights)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 111, in _get_weights\n",
      "    raise ValueError(\"weights not recognized: should be 'uniform', \"\n",
      "ValueError: weights not recognized: should be 'uniform', 'distance', or a callable function\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 4/10] END algorithm=auto, leaf_size=13, metric=minkowski, n_neighbors=8, p=1, weights=distane; total time=  15.4s\n",
      "[CV 2/3; 4/10] START algorithm=auto, leaf_size=13, metric=minkowski, n_neighbors=8, p=1, weights=distane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 206, in predict\n",
      "    weights = _get_weights(neigh_dist, self.weights)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 111, in _get_weights\n",
      "    raise ValueError(\"weights not recognized: should be 'uniform', \"\n",
      "ValueError: weights not recognized: should be 'uniform', 'distance', or a callable function\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 4/10] END algorithm=auto, leaf_size=13, metric=minkowski, n_neighbors=8, p=1, weights=distane; total time=  15.1s\n",
      "[CV 3/3; 4/10] START algorithm=auto, leaf_size=13, metric=minkowski, n_neighbors=8, p=1, weights=distane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 206, in predict\n",
      "    weights = _get_weights(neigh_dist, self.weights)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 111, in _get_weights\n",
      "    raise ValueError(\"weights not recognized: should be 'uniform', \"\n",
      "ValueError: weights not recognized: should be 'uniform', 'distance', or a callable function\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 4/10] END algorithm=auto, leaf_size=13, metric=minkowski, n_neighbors=8, p=1, weights=distane; total time=  15.1s\n",
      "[CV 1/3; 5/10] START algorithm=auto, leaf_size=7, metric=minkowski, n_neighbors=1, p=1, weights=distane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 206, in predict\n",
      "    weights = _get_weights(neigh_dist, self.weights)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 111, in _get_weights\n",
      "    raise ValueError(\"weights not recognized: should be 'uniform', \"\n",
      "ValueError: weights not recognized: should be 'uniform', 'distance', or a callable function\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 5/10] END algorithm=auto, leaf_size=7, metric=minkowski, n_neighbors=1, p=1, weights=distane; total time=  13.1s\n",
      "[CV 2/3; 5/10] START algorithm=auto, leaf_size=7, metric=minkowski, n_neighbors=1, p=1, weights=distane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 206, in predict\n",
      "    weights = _get_weights(neigh_dist, self.weights)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 111, in _get_weights\n",
      "    raise ValueError(\"weights not recognized: should be 'uniform', \"\n",
      "ValueError: weights not recognized: should be 'uniform', 'distance', or a callable function\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 5/10] END algorithm=auto, leaf_size=7, metric=minkowski, n_neighbors=1, p=1, weights=distane; total time=  13.3s\n",
      "[CV 3/3; 5/10] START algorithm=auto, leaf_size=7, metric=minkowski, n_neighbors=1, p=1, weights=distane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 206, in predict\n",
      "    weights = _get_weights(neigh_dist, self.weights)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 111, in _get_weights\n",
      "    raise ValueError(\"weights not recognized: should be 'uniform', \"\n",
      "ValueError: weights not recognized: should be 'uniform', 'distance', or a callable function\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 5/10] END algorithm=auto, leaf_size=7, metric=minkowski, n_neighbors=1, p=1, weights=distane; total time=  13.0s\n",
      "[CV 1/3; 6/10] START algorithm=auto, leaf_size=12, metric=minkowski, n_neighbors=17, p=2, weights=uniform\n",
      "[CV 1/3; 6/10] END algorithm=auto, leaf_size=12, metric=minkowski, n_neighbors=17, p=2, weights=uniform; total time=   4.8s\n",
      "[CV 2/3; 6/10] START algorithm=auto, leaf_size=12, metric=minkowski, n_neighbors=17, p=2, weights=uniform\n",
      "[CV 2/3; 6/10] END algorithm=auto, leaf_size=12, metric=minkowski, n_neighbors=17, p=2, weights=uniform; total time=   4.6s\n",
      "[CV 3/3; 6/10] START algorithm=auto, leaf_size=12, metric=minkowski, n_neighbors=17, p=2, weights=uniform\n",
      "[CV 3/3; 6/10] END algorithm=auto, leaf_size=12, metric=minkowski, n_neighbors=17, p=2, weights=uniform; total time=   4.8s\n",
      "[CV 1/3; 7/10] START algorithm=auto, leaf_size=12, metric=minkowski, n_neighbors=11, p=1, weights=uniform\n",
      "[CV 1/3; 7/10] END algorithm=auto, leaf_size=12, metric=minkowski, n_neighbors=11, p=1, weights=uniform; total time=  14.8s\n",
      "[CV 2/3; 7/10] START algorithm=auto, leaf_size=12, metric=minkowski, n_neighbors=11, p=1, weights=uniform\n",
      "[CV 2/3; 7/10] END algorithm=auto, leaf_size=12, metric=minkowski, n_neighbors=11, p=1, weights=uniform; total time=  15.1s\n",
      "[CV 3/3; 7/10] START algorithm=auto, leaf_size=12, metric=minkowski, n_neighbors=11, p=1, weights=uniform\n",
      "[CV 3/3; 7/10] END algorithm=auto, leaf_size=12, metric=minkowski, n_neighbors=11, p=1, weights=uniform; total time=  15.0s\n",
      "[CV 1/3; 8/10] START algorithm=auto, leaf_size=12, metric=minkowski, n_neighbors=1, p=2, weights=distane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 206, in predict\n",
      "    weights = _get_weights(neigh_dist, self.weights)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 111, in _get_weights\n",
      "    raise ValueError(\"weights not recognized: should be 'uniform', \"\n",
      "ValueError: weights not recognized: should be 'uniform', 'distance', or a callable function\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 8/10] END algorithm=auto, leaf_size=12, metric=minkowski, n_neighbors=1, p=2, weights=distane; total time=   2.5s\n",
      "[CV 2/3; 8/10] START algorithm=auto, leaf_size=12, metric=minkowski, n_neighbors=1, p=2, weights=distane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 206, in predict\n",
      "    weights = _get_weights(neigh_dist, self.weights)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 111, in _get_weights\n",
      "    raise ValueError(\"weights not recognized: should be 'uniform', \"\n",
      "ValueError: weights not recognized: should be 'uniform', 'distance', or a callable function\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 8/10] END algorithm=auto, leaf_size=12, metric=minkowski, n_neighbors=1, p=2, weights=distane; total time=   2.7s\n",
      "[CV 3/3; 8/10] START algorithm=auto, leaf_size=12, metric=minkowski, n_neighbors=1, p=2, weights=distane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 206, in predict\n",
      "    weights = _get_weights(neigh_dist, self.weights)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 111, in _get_weights\n",
      "    raise ValueError(\"weights not recognized: should be 'uniform', \"\n",
      "ValueError: weights not recognized: should be 'uniform', 'distance', or a callable function\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 8/10] END algorithm=auto, leaf_size=12, metric=minkowski, n_neighbors=1, p=2, weights=distane; total time=   2.7s\n",
      "[CV 1/3; 9/10] START algorithm=auto, leaf_size=11, metric=minkowski, n_neighbors=15, p=1, weights=distane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 206, in predict\n",
      "    weights = _get_weights(neigh_dist, self.weights)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 111, in _get_weights\n",
      "    raise ValueError(\"weights not recognized: should be 'uniform', \"\n",
      "ValueError: weights not recognized: should be 'uniform', 'distance', or a callable function\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 9/10] END algorithm=auto, leaf_size=11, metric=minkowski, n_neighbors=15, p=1, weights=distane; total time=  15.6s\n",
      "[CV 2/3; 9/10] START algorithm=auto, leaf_size=11, metric=minkowski, n_neighbors=15, p=1, weights=distane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 206, in predict\n",
      "    weights = _get_weights(neigh_dist, self.weights)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 111, in _get_weights\n",
      "    raise ValueError(\"weights not recognized: should be 'uniform', \"\n",
      "ValueError: weights not recognized: should be 'uniform', 'distance', or a callable function\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 9/10] END algorithm=auto, leaf_size=11, metric=minkowski, n_neighbors=15, p=1, weights=distane; total time=  15.3s\n",
      "[CV 3/3; 9/10] START algorithm=auto, leaf_size=11, metric=minkowski, n_neighbors=15, p=1, weights=distane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 206, in predict\n",
      "    weights = _get_weights(neigh_dist, self.weights)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 111, in _get_weights\n",
      "    raise ValueError(\"weights not recognized: should be 'uniform', \"\n",
      "ValueError: weights not recognized: should be 'uniform', 'distance', or a callable function\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 9/10] END algorithm=auto, leaf_size=11, metric=minkowski, n_neighbors=15, p=1, weights=distane; total time=  15.0s\n",
      "[CV 1/3; 10/10] START algorithm=auto, leaf_size=10, metric=minkowski, n_neighbors=14, p=2, weights=distane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 206, in predict\n",
      "    weights = _get_weights(neigh_dist, self.weights)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 111, in _get_weights\n",
      "    raise ValueError(\"weights not recognized: should be 'uniform', \"\n",
      "ValueError: weights not recognized: should be 'uniform', 'distance', or a callable function\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 10/10] END algorithm=auto, leaf_size=10, metric=minkowski, n_neighbors=14, p=2, weights=distane; total time=   4.7s\n",
      "[CV 2/3; 10/10] START algorithm=auto, leaf_size=10, metric=minkowski, n_neighbors=14, p=2, weights=distane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 206, in predict\n",
      "    weights = _get_weights(neigh_dist, self.weights)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 111, in _get_weights\n",
      "    raise ValueError(\"weights not recognized: should be 'uniform', \"\n",
      "ValueError: weights not recognized: should be 'uniform', 'distance', or a callable function\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 10/10] END algorithm=auto, leaf_size=10, metric=minkowski, n_neighbors=14, p=2, weights=distane; total time=   4.6s\n",
      "[CV 3/3; 10/10] START algorithm=auto, leaf_size=10, metric=minkowski, n_neighbors=14, p=2, weights=distane\n",
      "[CV 3/3; 10/10] END algorithm=auto, leaf_size=10, metric=minkowski, n_neighbors=14, p=2, weights=distane; total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 206, in predict\n",
      "    weights = _get_weights(neigh_dist, self.weights)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 111, in _get_weights\n",
      "    raise ValueError(\"weights not recognized: should be 'uniform', \"\n",
      "ValueError: weights not recognized: should be 'uniform', 'distance', or a callable function\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.83241491        nan        nan        nan 0.83363276\n",
      " 0.83582514        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'weights': 'uniform',\n",
       " 'p': 1,\n",
       " 'n_neighbors': 11,\n",
       " 'metric': 'minkowski',\n",
       " 'leaf_size': 12,\n",
       " 'algorithm': 'auto'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf= KNeighborsClassifier()\n",
    "\n",
    "#Hyperparameters\n",
    "\n",
    "n_neighbors= list(range(1,20))\n",
    "metric=['minkowski']\n",
    "p=[1,2]\n",
    "algorithm=['auto']\n",
    "weights=['uniform', 'distane']\n",
    "leaf_size=list(range(1,20))\n",
    "\n",
    "\n",
    "#Putting the hypreparameters in form of dictionary \n",
    "\n",
    "knn_hyperparameters= dict(n_neighbors= n_neighbors, \n",
    "                          metric=metric, \n",
    "                         weights=weights,\n",
    "                         algorithm=algorithm, \n",
    "                         p=p, \n",
    "                         leaf_size= leaf_size)\n",
    "\n",
    "\n",
    "knn_gridsearch= RandomizedSearchCV(estimator=knn_clf,\n",
    "                                  param_distributions=knn_hyperparameters, \n",
    "                                  cv=3, verbose=10)\n",
    "\n",
    "\n",
    "knn_gridsearch.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "knn_gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "649c594b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Confuision Matrix: \n",
      " [[6203 2163]\n",
      " [ 944 1638]]\n",
      "\n",
      " Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.74      0.80      8366\n",
      "           1       0.43      0.63      0.51      2582\n",
      "\n",
      "    accuracy                           0.72     10948\n",
      "   macro avg       0.65      0.69      0.66     10948\n",
      "weighted avg       0.76      0.72      0.73     10948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model will take some time to train. While it is at it we will make setup to evaluate the model\n",
    "\n",
    "#Predict the test tesults\n",
    "\n",
    "knn_y_predict= knn_gridsearch.predict(X_test)\n",
    "\n",
    "\n",
    "#Model Evaluation ; Confusion Matrix, Classification report, accuracy_score \n",
    "\n",
    "\n",
    "print ('\\n Confuision Matrix: \\n', confusion_matrix(y_test,knn_y_predict ))\n",
    "print ('\\n Classification Report: \\n', classification_report(y_test,knn_y_predict ))\n",
    "knn_accuracy= accuracy_score(y_test,knn_y_predict)\n",
    "\n",
    "#Append the value of accuracy in the dataframe that we created earlier \n",
    "\n",
    "result.loc[0]= ['KNN classifier', knn_accuracy]\n",
    "\n",
    "\n",
    "# Our model is still training... We wil wait for it to complete. \n",
    "#The above code will be reused by us in other modelels by using copy paste and modifying some values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df25b35",
   "metadata": {},
   "source": [
    "# 2) Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e002e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV 1/3; 1/10] START criterion=entropy, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
      "[CV 1/3; 1/10] END criterion=entropy, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV 2/3; 1/10] START criterion=entropy, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
      "[CV 2/3; 1/10] END criterion=entropy, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV 3/3; 1/10] START criterion=entropy, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
      "[CV 3/3; 1/10] END criterion=entropy, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV 1/3; 2/10] START criterion=gini, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
      "[CV 1/3; 2/10] END criterion=gini, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV 2/3; 2/10] START criterion=gini, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
      "[CV 2/3; 2/10] END criterion=gini, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV 3/3; 2/10] START criterion=gini, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
      "[CV 3/3; 2/10] END criterion=gini, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV 1/3; 3/10] START criterion=gini, max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
      "[CV 1/3; 3/10] END criterion=gini, max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV 2/3; 3/10] START criterion=gini, max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
      "[CV 2/3; 3/10] END criterion=gini, max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV 3/3; 3/10] START criterion=gini, max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
      "[CV 3/3; 3/10] END criterion=gini, max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV 1/3; 4/10] START criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
      "[CV 1/3; 4/10] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV 2/3; 4/10] START criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
      "[CV 2/3; 4/10] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV 3/3; 4/10] START criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
      "[CV 3/3; 4/10] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV 1/3; 5/10] START criterion=entropy, max_depth=40, max_features=auto, min_samples_leaf=4, min_samples_split=10, splitter=random\n",
      "[CV 1/3; 5/10] END criterion=entropy, max_depth=40, max_features=auto, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV 2/3; 5/10] START criterion=entropy, max_depth=40, max_features=auto, min_samples_leaf=4, min_samples_split=10, splitter=random\n",
      "[CV 2/3; 5/10] END criterion=entropy, max_depth=40, max_features=auto, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV 3/3; 5/10] START criterion=entropy, max_depth=40, max_features=auto, min_samples_leaf=4, min_samples_split=10, splitter=random\n",
      "[CV 3/3; 5/10] END criterion=entropy, max_depth=40, max_features=auto, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV 1/3; 6/10] START criterion=gini, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=10, splitter=best\n",
      "[CV 1/3; 6/10] END criterion=gini, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV 2/3; 6/10] START criterion=gini, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=10, splitter=best\n",
      "[CV 2/3; 6/10] END criterion=gini, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV 3/3; 6/10] START criterion=gini, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=10, splitter=best\n",
      "[CV 3/3; 6/10] END criterion=gini, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV 1/3; 7/10] START criterion=gini, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
      "[CV 1/3; 7/10] END criterion=gini, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV 2/3; 7/10] START criterion=gini, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
      "[CV 2/3; 7/10] END criterion=gini, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV 3/3; 7/10] START criterion=gini, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
      "[CV 3/3; 7/10] END criterion=gini, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV 1/3; 8/10] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
      "[CV 1/3; 8/10] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV 2/3; 8/10] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
      "[CV 2/3; 8/10] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV 3/3; 8/10] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
      "[CV 3/3; 8/10] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV 1/3; 9/10] START criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
      "[CV 1/3; 9/10] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV 2/3; 9/10] START criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
      "[CV 2/3; 9/10] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV 3/3; 9/10] START criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
      "[CV 3/3; 9/10] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV 1/3; 10/10] START criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
      "[CV 1/3; 10/10] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV 2/3; 10/10] START criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
      "[CV 2/3; 10/10] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV 3/3; 10/10] START criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
      "[CV 3/3; 10/10] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=DecisionTreeClassifier(),\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90],\n",
       "                                        'max_features': ['auto', 'sqrt', 'log2',\n",
       "                                                         None],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'splitter': ['best', 'random']},\n",
       "                   verbose=10)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_clf= DecisionTreeClassifier()\n",
    "\n",
    "#Hyperparameters\n",
    "\n",
    "criterion=['gini', 'entropy']\n",
    "splitter=['best', 'random']\n",
    "\n",
    "min_samples_leaf=[1,2,4]\n",
    "min_samples_split=[2,5,10]\n",
    "\n",
    "max_depth= list(range(10,100, 10))\n",
    "max_features=['auto', 'sqrt', 'log2', None]\n",
    "\n",
    "#Putting hyperparameters in form of dictionary \n",
    "\n",
    "dt_hyperparameters= dict(criterion=criterion,\n",
    "                         splitter=splitter, \n",
    "                         min_samples_leaf=min_samples_leaf,\n",
    "                         min_samples_split=min_samples_split,\n",
    "                         max_depth=max_depth,\n",
    "                         max_features=max_features)\n",
    "                         \n",
    "    \n",
    "dt_gridsearch= RandomizedSearchCV(estimator= dt_clf, \n",
    "                                  param_distributions=dt_hyperparameters, \n",
    "                                 cv=3, verbose=10)\n",
    "\n",
    "#Fit the train in GRidSearch \n",
    "\n",
    "dt_gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "35a0a2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'splitter': 'best',\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 10,\n",
       " 'criterion': 'entropy'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f269da52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Confuision Matrix: \n",
      " [[6372 1994]\n",
      " [ 653 1929]]\n",
      "\n",
      " Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.76      0.83      8366\n",
      "           1       0.49      0.75      0.59      2582\n",
      "\n",
      "    accuracy                           0.76     10948\n",
      "   macro avg       0.70      0.75      0.71     10948\n",
      "weighted avg       0.81      0.76      0.77     10948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of the model \n",
    "\n",
    "#Predict the test tesults\n",
    "\n",
    "dt_y_predict= dt_gridsearch.predict(X_test)\n",
    "\n",
    "\n",
    "#Model Evaluation ; Confusion Matrix, Classification report, accuracy_score \n",
    "\n",
    "\n",
    "print ('\\n Confuision Matrix: \\n', confusion_matrix(y_test,dt_y_predict ))\n",
    "print ('\\n Classification Report: \\n', classification_report(y_test,dt_y_predict ))\n",
    "dt_accuracy= accuracy_score(y_test, dt_y_predict)\n",
    "\n",
    "#Append the value of accuracy in the dataframe that we created earlier \n",
    "\n",
    "result.loc[1]= ['Decision Tree classifier', dt_accuracy]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "39853b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN classifier</td>\n",
       "      <td>0.716204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree classifier</td>\n",
       "      <td>0.758221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  Accuracy Score\n",
       "0            KNN classifier        0.716204\n",
       "1  Decision Tree classifier        0.758221"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aecf537",
   "metadata": {},
   "source": [
    "# 3) Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f63f49e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV 1/3; 1/10] START bootstrap=False, criterion=gini, max_depth=50, max_features=auto, min_samples_leaf=4, min_samples_split=2\n",
      "[CV 1/3; 1/10] END bootstrap=False, criterion=gini, max_depth=50, max_features=auto, min_samples_leaf=4, min_samples_split=2; total time=   2.1s\n",
      "[CV 2/3; 1/10] START bootstrap=False, criterion=gini, max_depth=50, max_features=auto, min_samples_leaf=4, min_samples_split=2\n",
      "[CV 2/3; 1/10] END bootstrap=False, criterion=gini, max_depth=50, max_features=auto, min_samples_leaf=4, min_samples_split=2; total time=   1.9s\n",
      "[CV 3/3; 1/10] START bootstrap=False, criterion=gini, max_depth=50, max_features=auto, min_samples_leaf=4, min_samples_split=2\n",
      "[CV 3/3; 1/10] END bootstrap=False, criterion=gini, max_depth=50, max_features=auto, min_samples_leaf=4, min_samples_split=2; total time=   1.9s\n",
      "[CV 1/3; 2/10] START bootstrap=False, criterion=gini, max_depth=60, max_features=auto, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 1/3; 2/10] END bootstrap=False, criterion=gini, max_depth=60, max_features=auto, min_samples_leaf=1, min_samples_split=2; total time=   2.8s\n",
      "[CV 2/3; 2/10] START bootstrap=False, criterion=gini, max_depth=60, max_features=auto, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 2/3; 2/10] END bootstrap=False, criterion=gini, max_depth=60, max_features=auto, min_samples_leaf=1, min_samples_split=2; total time=   2.7s\n",
      "[CV 3/3; 2/10] START bootstrap=False, criterion=gini, max_depth=60, max_features=auto, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 3/3; 2/10] END bootstrap=False, criterion=gini, max_depth=60, max_features=auto, min_samples_leaf=1, min_samples_split=2; total time=   2.9s\n",
      "[CV 1/3; 3/10] START bootstrap=True, criterion=entropy, max_depth=40, max_features=auto, min_samples_leaf=4, min_samples_split=5\n",
      "[CV 1/3; 3/10] END bootstrap=True, criterion=entropy, max_depth=40, max_features=auto, min_samples_leaf=4, min_samples_split=5; total time=   1.4s\n",
      "[CV 2/3; 3/10] START bootstrap=True, criterion=entropy, max_depth=40, max_features=auto, min_samples_leaf=4, min_samples_split=5\n",
      "[CV 2/3; 3/10] END bootstrap=True, criterion=entropy, max_depth=40, max_features=auto, min_samples_leaf=4, min_samples_split=5; total time=   1.3s\n",
      "[CV 3/3; 3/10] START bootstrap=True, criterion=entropy, max_depth=40, max_features=auto, min_samples_leaf=4, min_samples_split=5\n",
      "[CV 3/3; 3/10] END bootstrap=True, criterion=entropy, max_depth=40, max_features=auto, min_samples_leaf=4, min_samples_split=5; total time=   1.4s\n",
      "[CV 1/3; 4/10] START bootstrap=False, criterion=entropy, max_depth=90, max_features=auto, min_samples_leaf=4, min_samples_split=10\n",
      "[CV 1/3; 4/10] END bootstrap=False, criterion=entropy, max_depth=90, max_features=auto, min_samples_leaf=4, min_samples_split=10; total time=   2.1s\n",
      "[CV 2/3; 4/10] START bootstrap=False, criterion=entropy, max_depth=90, max_features=auto, min_samples_leaf=4, min_samples_split=10\n",
      "[CV 2/3; 4/10] END bootstrap=False, criterion=entropy, max_depth=90, max_features=auto, min_samples_leaf=4, min_samples_split=10; total time=   2.2s\n",
      "[CV 3/3; 4/10] START bootstrap=False, criterion=entropy, max_depth=90, max_features=auto, min_samples_leaf=4, min_samples_split=10\n",
      "[CV 3/3; 4/10] END bootstrap=False, criterion=entropy, max_depth=90, max_features=auto, min_samples_leaf=4, min_samples_split=10; total time=   1.9s\n",
      "[CV 1/3; 5/10] START bootstrap=False, criterion=gini, max_depth=70, max_features=auto, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 1/3; 5/10] END bootstrap=False, criterion=gini, max_depth=70, max_features=auto, min_samples_leaf=1, min_samples_split=10; total time=   2.4s\n",
      "[CV 2/3; 5/10] START bootstrap=False, criterion=gini, max_depth=70, max_features=auto, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 2/3; 5/10] END bootstrap=False, criterion=gini, max_depth=70, max_features=auto, min_samples_leaf=1, min_samples_split=10; total time=   2.3s\n",
      "[CV 3/3; 5/10] START bootstrap=False, criterion=gini, max_depth=70, max_features=auto, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 3/3; 5/10] END bootstrap=False, criterion=gini, max_depth=70, max_features=auto, min_samples_leaf=1, min_samples_split=10; total time=   2.3s\n",
      "[CV 1/3; 6/10] START bootstrap=False, criterion=gini, max_depth=80, max_features=sqrt, min_samples_leaf=1, min_samples_split=5\n",
      "[CV 1/3; 6/10] END bootstrap=False, criterion=gini, max_depth=80, max_features=sqrt, min_samples_leaf=1, min_samples_split=5; total time=   2.4s\n",
      "[CV 2/3; 6/10] START bootstrap=False, criterion=gini, max_depth=80, max_features=sqrt, min_samples_leaf=1, min_samples_split=5\n",
      "[CV 2/3; 6/10] END bootstrap=False, criterion=gini, max_depth=80, max_features=sqrt, min_samples_leaf=1, min_samples_split=5; total time=   2.3s\n",
      "[CV 3/3; 6/10] START bootstrap=False, criterion=gini, max_depth=80, max_features=sqrt, min_samples_leaf=1, min_samples_split=5\n",
      "[CV 3/3; 6/10] END bootstrap=False, criterion=gini, max_depth=80, max_features=sqrt, min_samples_leaf=1, min_samples_split=5; total time=   2.7s\n",
      "[CV 1/3; 7/10] START bootstrap=True, criterion=entropy, max_depth=40, max_features=sqrt, min_samples_leaf=4, min_samples_split=10\n",
      "[CV 1/3; 7/10] END bootstrap=True, criterion=entropy, max_depth=40, max_features=sqrt, min_samples_leaf=4, min_samples_split=10; total time=   1.3s\n",
      "[CV 2/3; 7/10] START bootstrap=True, criterion=entropy, max_depth=40, max_features=sqrt, min_samples_leaf=4, min_samples_split=10\n",
      "[CV 2/3; 7/10] END bootstrap=True, criterion=entropy, max_depth=40, max_features=sqrt, min_samples_leaf=4, min_samples_split=10; total time=   1.6s\n",
      "[CV 3/3; 7/10] START bootstrap=True, criterion=entropy, max_depth=40, max_features=sqrt, min_samples_leaf=4, min_samples_split=10\n",
      "[CV 3/3; 7/10] END bootstrap=True, criterion=entropy, max_depth=40, max_features=sqrt, min_samples_leaf=4, min_samples_split=10; total time=   1.4s\n",
      "[CV 1/3; 8/10] START bootstrap=True, criterion=entropy, max_depth=90, max_features=auto, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 1/3; 8/10] END bootstrap=True, criterion=entropy, max_depth=90, max_features=auto, min_samples_leaf=1, min_samples_split=2; total time=   2.0s\n",
      "[CV 2/3; 8/10] START bootstrap=True, criterion=entropy, max_depth=90, max_features=auto, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 2/3; 8/10] END bootstrap=True, criterion=entropy, max_depth=90, max_features=auto, min_samples_leaf=1, min_samples_split=2; total time=   1.8s\n",
      "[CV 3/3; 8/10] START bootstrap=True, criterion=entropy, max_depth=90, max_features=auto, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 3/3; 8/10] END bootstrap=True, criterion=entropy, max_depth=90, max_features=auto, min_samples_leaf=1, min_samples_split=2; total time=   1.9s\n",
      "[CV 1/3; 9/10] START bootstrap=True, criterion=gini, max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=10\n",
      "[CV 1/3; 9/10] END bootstrap=True, criterion=gini, max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=10; total time=   1.4s\n",
      "[CV 2/3; 9/10] START bootstrap=True, criterion=gini, max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=10\n",
      "[CV 2/3; 9/10] END bootstrap=True, criterion=gini, max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=10; total time=   1.4s\n",
      "[CV 3/3; 9/10] START bootstrap=True, criterion=gini, max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=10\n",
      "[CV 3/3; 9/10] END bootstrap=True, criterion=gini, max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=10; total time=   1.5s\n",
      "[CV 1/3; 10/10] START bootstrap=False, criterion=entropy, max_depth=70, max_features=auto, min_samples_leaf=1, min_samples_split=5\n",
      "[CV 1/3; 10/10] END bootstrap=False, criterion=entropy, max_depth=70, max_features=auto, min_samples_leaf=1, min_samples_split=5; total time=   2.4s\n",
      "[CV 2/3; 10/10] START bootstrap=False, criterion=entropy, max_depth=70, max_features=auto, min_samples_leaf=1, min_samples_split=5\n",
      "[CV 2/3; 10/10] END bootstrap=False, criterion=entropy, max_depth=70, max_features=auto, min_samples_leaf=1, min_samples_split=5; total time=   2.4s\n",
      "[CV 3/3; 10/10] START bootstrap=False, criterion=entropy, max_depth=70, max_features=auto, min_samples_leaf=1, min_samples_split=5\n",
      "[CV 3/3; 10/10] END bootstrap=False, criterion=entropy, max_depth=70, max_features=auto, min_samples_leaf=1, min_samples_split=5; total time=   2.6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'min_samples_split': 2,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 50,\n",
       " 'criterion': 'gini',\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf= RandomForestClassifier()\n",
    "\n",
    "#Hyperparameters \n",
    "\n",
    "criterion=['gini', 'entropy']\n",
    "max_depth=list(range(10,100,10))\n",
    "min_samples_leaf=[1,2,4]\n",
    "min_samples_split=[2,5,10]\n",
    "\n",
    "max_features =['auto', 'sqrt']\n",
    "bootstrap=[True, False]\n",
    "\n",
    "\n",
    "\n",
    "#Putting the hyperparameters in a dictionary \n",
    "\n",
    "rf_hyperparameters= dict(criterion=criterion,\n",
    "                        max_depth=max_depth,\n",
    "                        min_samples_leaf=min_samples_leaf,\n",
    "                        min_samples_split=min_samples_split,\n",
    "                        max_features=max_features,\n",
    "                        bootstrap= bootstrap)\n",
    "\n",
    "rf_gridsearch= RandomizedSearchCV(estimator= rf_clf,\n",
    "                                 param_distributions= rf_hyperparameters, \n",
    "                                 cv=3, verbose=10)\n",
    "\n",
    "\n",
    "#Fit the gridsearch of train data \n",
    "\n",
    "rf_gridsearch.fit(X_train, y_train)\n",
    "\n",
    "rf_gridsearch.best_params_\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a4cb69ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Confuision Matrix: \n",
      " [[6281 2085]\n",
      " [ 590 1992]]\n",
      "\n",
      " Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.75      0.82      8366\n",
      "           1       0.49      0.77      0.60      2582\n",
      "\n",
      "    accuracy                           0.76     10948\n",
      "   macro avg       0.70      0.76      0.71     10948\n",
      "weighted avg       0.81      0.76      0.77     10948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of the model \n",
    "\n",
    "#Predict the test tesults\n",
    "\n",
    "rf_y_predict= rf_gridsearch.predict(X_test)\n",
    "\n",
    "\n",
    "#Model Evaluation ; Confusion Matrix, Classification report, accuracy_score \n",
    "\n",
    "\n",
    "print ('\\n Confuision Matrix: \\n', confusion_matrix(y_test,rf_y_predict ))\n",
    "print ('\\n Classification Report: \\n', classification_report(y_test,rf_y_predict ))\n",
    "rf_accuracy= accuracy_score(y_test, rf_y_predict)\n",
    "\n",
    "#Append the value of accuracy in the dataframe that we created earlier \n",
    "\n",
    "result.loc[2]= ['RandomForest classifier', rf_accuracy]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7938b73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN classifier</td>\n",
       "      <td>0.716204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree classifier</td>\n",
       "      <td>0.758221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest classifier</td>\n",
       "      <td>0.755663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  Accuracy Score\n",
       "0            KNN classifier        0.716204\n",
       "1  Decision Tree classifier        0.758221\n",
       "2   RandomForest classifier        0.755663"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01246d7",
   "metadata": {},
   "source": [
    "# 4) Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ba19a2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV 1/3; 1/10] START C=0.2682695795279725, max_iter=2000, penalty=elasticnet, solver=liblinear\n",
      "[CV 1/3; 1/10] END C=0.2682695795279725, max_iter=2000, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV 2/3; 1/10] START C=0.2682695795279725, max_iter=2000, penalty=elasticnet, solver=liblinear\n",
      "[CV 2/3; 1/10] END C=0.2682695795279725, max_iter=2000, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV 3/3; 1/10] START C=0.2682695795279725, max_iter=2000, penalty=elasticnet, solver=liblinear\n",
      "[CV 3/3; 1/10] END C=0.2682695795279725, max_iter=2000, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV 1/3; 2/10] START C=2.559547922699533, max_iter=1000, penalty=elasticnet, solver=newton-cg\n",
      "[CV 1/3; 2/10] END C=2.559547922699533, max_iter=1000, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV 2/3; 2/10] START C=2.559547922699533, max_iter=1000, penalty=elasticnet, solver=newton-cg\n",
      "[CV 2/3; 2/10] END C=2.559547922699533, max_iter=1000, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV 3/3; 2/10] START C=2.559547922699533, max_iter=1000, penalty=elasticnet, solver=newton-cg\n",
      "[CV 3/3; 2/10] END C=2.559547922699533, max_iter=1000, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV 1/3; 3/10] START C=0.18420699693267145, max_iter=2000, penalty=l2, solver=liblinear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 3/10] END C=0.18420699693267145, max_iter=2000, penalty=l2, solver=liblinear; total time=   0.4s\n",
      "[CV 2/3; 3/10] START C=0.18420699693267145, max_iter=2000, penalty=l2, solver=liblinear\n",
      "[CV 2/3; 3/10] END C=0.18420699693267145, max_iter=2000, penalty=l2, solver=liblinear; total time=   0.4s\n",
      "[CV 3/3; 3/10] START C=0.18420699693267145, max_iter=2000, penalty=l2, solver=liblinear\n",
      "[CV 3/3; 3/10] END C=0.18420699693267145, max_iter=2000, penalty=l2, solver=liblinear; total time=   0.4s\n",
      "[CV 1/3; 4/10] START C=232.99518105153672, max_iter=2000, penalty=None, solver=saga\n",
      "[CV 1/3; 4/10] END C=232.99518105153672, max_iter=2000, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV 2/3; 4/10] START C=232.99518105153672, max_iter=2000, penalty=None, solver=saga\n",
      "[CV 2/3; 4/10] END C=232.99518105153672, max_iter=2000, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV 3/3; 4/10] START C=232.99518105153672, max_iter=2000, penalty=None, solver=saga\n",
      "[CV 3/3; 4/10] END C=232.99518105153672, max_iter=2000, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV 1/3; 5/10] START C=0.05963623316594643, max_iter=5000, penalty=l2, solver=lbfgs\n",
      "[CV 1/3; 5/10] END C=0.05963623316594643, max_iter=5000, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV 2/3; 5/10] START C=0.05963623316594643, max_iter=5000, penalty=l2, solver=lbfgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 439, in _check_solver\n",
      "    raise ValueError(\"Logistic Regression supports only penalties in %s,\"\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 439, in _check_solver\n",
      "    raise ValueError(\"Logistic Regression supports only penalties in %s,\"\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 439, in _check_solver\n",
      "    raise ValueError(\"Logistic Regression supports only penalties in %s,\"\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 5/10] END C=0.05963623316594643, max_iter=5000, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 3/3; 5/10] START C=0.05963623316594643, max_iter=5000, penalty=l2, solver=lbfgs\n",
      "[CV 3/3; 5/10] END C=0.05963623316594643, max_iter=5000, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 1/3; 6/10] START C=719.6856730011514, max_iter=5000, penalty=l1, solver=newton-cg\n",
      "[CV 1/3; 6/10] END C=719.6856730011514, max_iter=5000, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 2/3; 6/10] START C=719.6856730011514, max_iter=5000, penalty=l1, solver=newton-cg\n",
      "[CV 2/3; 6/10] END C=719.6856730011514, max_iter=5000, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 3/3; 6/10] START C=719.6856730011514, max_iter=5000, penalty=l1, solver=newton-cg\n",
      "[CV 3/3; 6/10] END C=719.6856730011514, max_iter=5000, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 1/3; 7/10] START C=2222.996482526191, max_iter=100, penalty=l2, solver=liblinear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 7/10] END C=2222.996482526191, max_iter=100, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV 2/3; 7/10] START C=2222.996482526191, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 2/3; 7/10] END C=2222.996482526191, max_iter=100, penalty=l2, solver=liblinear; total time=   0.4s\n",
      "[CV 3/3; 7/10] START C=2222.996482526191, max_iter=100, penalty=l2, solver=liblinear\n",
      "[CV 3/3; 7/10] END C=2222.996482526191, max_iter=100, penalty=l2, solver=liblinear; total time=   0.4s\n",
      "[CV 1/3; 8/10] START C=339.3221771895323, max_iter=5000, penalty=elasticnet, solver=saga\n",
      "[CV 1/3; 8/10] END C=339.3221771895323, max_iter=5000, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV 2/3; 8/10] START C=339.3221771895323, max_iter=5000, penalty=elasticnet, solver=saga\n",
      "[CV 2/3; 8/10] END C=339.3221771895323, max_iter=5000, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV 3/3; 8/10] START C=339.3221771895323, max_iter=5000, penalty=elasticnet, solver=saga\n",
      "[CV 3/3; 8/10] END C=339.3221771895323, max_iter=5000, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV 1/3; 9/10] START C=0.8286427728546842, max_iter=5000, penalty=l2, solver=liblinear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 9/10] END C=0.8286427728546842, max_iter=5000, penalty=l2, solver=liblinear; total time=   0.4s\n",
      "[CV 2/3; 9/10] START C=0.8286427728546842, max_iter=5000, penalty=l2, solver=liblinear\n",
      "[CV 2/3; 9/10] END C=0.8286427728546842, max_iter=5000, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV 3/3; 9/10] START C=0.8286427728546842, max_iter=5000, penalty=l2, solver=liblinear\n",
      "[CV 3/3; 9/10] END C=0.8286427728546842, max_iter=5000, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV 1/3; 10/10] START C=0.013257113655901081, max_iter=2000, penalty=l2, solver=lbfgs\n",
      "[CV 1/3; 10/10] END C=0.013257113655901081, max_iter=2000, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 2/3; 10/10] START C=0.013257113655901081, max_iter=2000, penalty=l2, solver=lbfgs\n",
      "[CV 2/3; 10/10] END C=0.013257113655901081, max_iter=2000, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 3/3; 10/10] START C=0.013257113655901081, max_iter=2000, penalty=l2, solver=lbfgs\n",
      "[CV 3/3; 10/10] END C=0.013257113655901081, max_iter=2000, penalty=l2, solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.85098815        nan 0.85098815        nan\n",
      " 0.8508968         nan 0.850775   0.85074455]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'solver': 'liblinear',\n",
       " 'penalty': 'l2',\n",
       " 'max_iter': 2000,\n",
       " 'C': 0.18420699693267145}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "lr=LogisticRegression()\n",
    "\n",
    "\n",
    "#Hyperparameters for Logistic Regression \n",
    "\n",
    "penalty=['l1', 'l2', 'elasticnet', None]\n",
    "C=np.logspace(-4,4,50)\n",
    "solver= ['lbfgs', 'newton-cg', 'liblinear', 'sag', 'saga']\n",
    "max_iter= [100,500,1000,2000,5000]\n",
    "\n",
    "\n",
    "lr_hyperparameters= dict(penalty=penalty,\n",
    "                        C=C,\n",
    "                        solver=solver,\n",
    "                        max_iter=max_iter)\n",
    "\n",
    "\n",
    "lr_gridsearch= RandomizedSearchCV(estimator = lr,\n",
    "                                 param_distributions= lr_hyperparameters, \n",
    "                                 cv=3, verbose=10)\n",
    "\n",
    "lr_gridsearch.fit(X_train,y_train)\n",
    "\n",
    "lr_gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5f8ed99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Confuision Matrix: \n",
      " [[   0 8366]\n",
      " [   0 2582]]\n",
      "\n",
      " Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      8366\n",
      "           1       0.24      1.00      0.38      2582\n",
      "\n",
      "    accuracy                           0.24     10948\n",
      "   macro avg       0.12      0.50      0.19     10948\n",
      "weighted avg       0.06      0.24      0.09     10948\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Predict the test tesults\n",
    "\n",
    "lr_y_predict= lr_gridsearch.predict(X_test)\n",
    "\n",
    "\n",
    "#Model Evaluation ; Confusion Matrix, Classification report, accuracy_score \n",
    "\n",
    "\n",
    "print ('\\n Confuision Matrix: \\n', confusion_matrix(y_test,lr_y_predict ))\n",
    "print ('\\n Classification Report: \\n', classification_report(y_test,lr_y_predict ))\n",
    "lr_accuracy= accuracy_score(y_test, lr_y_predict)\n",
    "\n",
    "#Append the value of accuracy in the dataframe that we created earlier \n",
    "\n",
    "result.loc[3]= ['Logistic Regression', lr_accuracy]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "27b19fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN classifier</td>\n",
       "      <td>0.716204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree classifier</td>\n",
       "      <td>0.758221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest classifier</td>\n",
       "      <td>0.755663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.235842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  Accuracy Score\n",
       "0            KNN classifier        0.716204\n",
       "1  Decision Tree classifier        0.758221\n",
       "2   RandomForest classifier        0.755663\n",
       "3       Logistic Regression        0.235842"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bf79cc",
   "metadata": {},
   "source": [
    "## 5) XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ea579730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV 1/3; 1/10] START booster=gblinear, gamma=51.2, learning_rate=0.6033333333333334, max_depth=6, n_estimators=900, reg_alpha=12.8, reg_lambda=0.2\n",
      "[19:30:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/3; 1/10] END booster=gblinear, gamma=51.2, learning_rate=0.6033333333333334, max_depth=6, n_estimators=900, reg_alpha=12.8, reg_lambda=0.2; total time=   1.8s\n",
      "[CV 2/3; 1/10] START booster=gblinear, gamma=51.2, learning_rate=0.6033333333333334, max_depth=6, n_estimators=900, reg_alpha=12.8, reg_lambda=0.2\n",
      "[19:30:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/3; 1/10] END booster=gblinear, gamma=51.2, learning_rate=0.6033333333333334, max_depth=6, n_estimators=900, reg_alpha=12.8, reg_lambda=0.2; total time=   1.9s\n",
      "[CV 3/3; 1/10] START booster=gblinear, gamma=51.2, learning_rate=0.6033333333333334, max_depth=6, n_estimators=900, reg_alpha=12.8, reg_lambda=0.2\n",
      "[19:30:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/3; 1/10] END booster=gblinear, gamma=51.2, learning_rate=0.6033333333333334, max_depth=6, n_estimators=900, reg_alpha=12.8, reg_lambda=0.2; total time=   2.1s\n",
      "[CV 1/3; 2/10] START booster=gblinear, gamma=3.2, learning_rate=0.34375000000000006, max_depth=15, n_estimators=700, reg_alpha=12.8, reg_lambda=0.1\n",
      "[19:30:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/3; 2/10] END booster=gblinear, gamma=3.2, learning_rate=0.34375000000000006, max_depth=15, n_estimators=700, reg_alpha=12.8, reg_lambda=0.1; total time=   1.6s\n",
      "[CV 2/3; 2/10] START booster=gblinear, gamma=3.2, learning_rate=0.34375000000000006, max_depth=15, n_estimators=700, reg_alpha=12.8, reg_lambda=0.1\n",
      "[19:30:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/3; 2/10] END booster=gblinear, gamma=3.2, learning_rate=0.34375000000000006, max_depth=15, n_estimators=700, reg_alpha=12.8, reg_lambda=0.1; total time=   1.6s\n",
      "[CV 3/3; 2/10] START booster=gblinear, gamma=3.2, learning_rate=0.34375000000000006, max_depth=15, n_estimators=700, reg_alpha=12.8, reg_lambda=0.1\n",
      "[19:30:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/3; 2/10] END booster=gblinear, gamma=3.2, learning_rate=0.34375000000000006, max_depth=15, n_estimators=700, reg_alpha=12.8, reg_lambda=0.1; total time=   1.4s\n",
      "[CV 1/3; 3/10] START booster=gblinear, gamma=102.4, learning_rate=0.26958333333333334, max_depth=3, n_estimators=700, reg_alpha=25.6, reg_lambda=25.6\n",
      "[19:30:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/3; 3/10] END booster=gblinear, gamma=102.4, learning_rate=0.26958333333333334, max_depth=3, n_estimators=700, reg_alpha=25.6, reg_lambda=25.6; total time=   1.5s\n",
      "[CV 2/3; 3/10] START booster=gblinear, gamma=102.4, learning_rate=0.26958333333333334, max_depth=3, n_estimators=700, reg_alpha=25.6, reg_lambda=25.6\n",
      "[19:30:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/3; 3/10] END booster=gblinear, gamma=102.4, learning_rate=0.26958333333333334, max_depth=3, n_estimators=700, reg_alpha=25.6, reg_lambda=25.6; total time=   1.4s\n",
      "[CV 3/3; 3/10] START booster=gblinear, gamma=102.4, learning_rate=0.26958333333333334, max_depth=3, n_estimators=700, reg_alpha=25.6, reg_lambda=25.6\n",
      "[19:30:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/3; 3/10] END booster=gblinear, gamma=102.4, learning_rate=0.26958333333333334, max_depth=3, n_estimators=700, reg_alpha=25.6, reg_lambda=25.6; total time=   1.4s\n",
      "[CV 1/3; 4/10] START booster=gblinear, gamma=0.4, learning_rate=0.7516666666666667, max_depth=6, n_estimators=400, reg_alpha=0.4, reg_lambda=102.4\n",
      "[19:30:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/3; 4/10] END booster=gblinear, gamma=0.4, learning_rate=0.7516666666666667, max_depth=6, n_estimators=400, reg_alpha=0.4, reg_lambda=102.4; total time=   1.0s\n",
      "[CV 2/3; 4/10] START booster=gblinear, gamma=0.4, learning_rate=0.7516666666666667, max_depth=6, n_estimators=400, reg_alpha=0.4, reg_lambda=102.4\n",
      "[19:30:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/3; 4/10] END booster=gblinear, gamma=0.4, learning_rate=0.7516666666666667, max_depth=6, n_estimators=400, reg_alpha=0.4, reg_lambda=102.4; total time=   0.8s\n",
      "[CV 3/3; 4/10] START booster=gblinear, gamma=0.4, learning_rate=0.7516666666666667, max_depth=6, n_estimators=400, reg_alpha=0.4, reg_lambda=102.4\n",
      "[19:30:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 4/10] END booster=gblinear, gamma=0.4, learning_rate=0.7516666666666667, max_depth=6, n_estimators=400, reg_alpha=0.4, reg_lambda=102.4; total time=   0.8s\n",
      "[CV 1/3; 5/10] START booster=gbtree, gamma=0.8, learning_rate=0.01, max_depth=9, n_estimators=900, reg_alpha=0.4, reg_lambda=12.8\n",
      "[CV 1/3; 5/10] END booster=gbtree, gamma=0.8, learning_rate=0.01, max_depth=9, n_estimators=900, reg_alpha=0.4, reg_lambda=12.8; total time=  17.2s\n",
      "[CV 2/3; 5/10] START booster=gbtree, gamma=0.8, learning_rate=0.01, max_depth=9, n_estimators=900, reg_alpha=0.4, reg_lambda=12.8\n",
      "[CV 2/3; 5/10] END booster=gbtree, gamma=0.8, learning_rate=0.01, max_depth=9, n_estimators=900, reg_alpha=0.4, reg_lambda=12.8; total time=  17.8s\n",
      "[CV 3/3; 5/10] START booster=gbtree, gamma=0.8, learning_rate=0.01, max_depth=9, n_estimators=900, reg_alpha=0.4, reg_lambda=12.8\n",
      "[CV 3/3; 5/10] END booster=gbtree, gamma=0.8, learning_rate=0.01, max_depth=9, n_estimators=900, reg_alpha=0.4, reg_lambda=12.8; total time=  17.4s\n",
      "[CV 1/3; 6/10] START booster=gblinear, gamma=0.2, learning_rate=0.9, max_depth=12, n_estimators=300, reg_alpha=0.2, reg_lambda=1.6\n",
      "[19:31:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/3; 6/10] END booster=gblinear, gamma=0.2, learning_rate=0.9, max_depth=12, n_estimators=300, reg_alpha=0.2, reg_lambda=1.6; total time=   0.8s\n",
      "[CV 2/3; 6/10] START booster=gblinear, gamma=0.2, learning_rate=0.9, max_depth=12, n_estimators=300, reg_alpha=0.2, reg_lambda=1.6\n",
      "[19:31:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/3; 6/10] END booster=gblinear, gamma=0.2, learning_rate=0.9, max_depth=12, n_estimators=300, reg_alpha=0.2, reg_lambda=1.6; total time=   0.7s\n",
      "[CV 3/3; 6/10] START booster=gblinear, gamma=0.2, learning_rate=0.9, max_depth=12, n_estimators=300, reg_alpha=0.2, reg_lambda=1.6\n",
      "[19:31:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/3; 6/10] END booster=gblinear, gamma=0.2, learning_rate=0.9, max_depth=12, n_estimators=300, reg_alpha=0.2, reg_lambda=1.6; total time=   0.8s\n",
      "[CV 1/3; 7/10] START booster=gblinear, gamma=3.2, learning_rate=0.34375000000000006, max_depth=6, n_estimators=700, reg_alpha=25.6, reg_lambda=25.6\n",
      "[19:31:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/3; 7/10] END booster=gblinear, gamma=3.2, learning_rate=0.34375000000000006, max_depth=6, n_estimators=700, reg_alpha=25.6, reg_lambda=25.6; total time=   1.7s\n",
      "[CV 2/3; 7/10] START booster=gblinear, gamma=3.2, learning_rate=0.34375000000000006, max_depth=6, n_estimators=700, reg_alpha=25.6, reg_lambda=25.6\n",
      "[19:31:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/3; 7/10] END booster=gblinear, gamma=3.2, learning_rate=0.34375000000000006, max_depth=6, n_estimators=700, reg_alpha=25.6, reg_lambda=25.6; total time=   1.7s\n",
      "[CV 3/3; 7/10] START booster=gblinear, gamma=3.2, learning_rate=0.34375000000000006, max_depth=6, n_estimators=700, reg_alpha=25.6, reg_lambda=25.6\n",
      "[19:31:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/3; 7/10] END booster=gblinear, gamma=3.2, learning_rate=0.34375000000000006, max_depth=6, n_estimators=700, reg_alpha=25.6, reg_lambda=25.6; total time=   1.7s\n",
      "[CV 1/3; 8/10] START booster=gblinear, gamma=102.4, learning_rate=0.38083333333333336, max_depth=3, n_estimators=800, reg_alpha=102.4, reg_lambda=0.8\n",
      "[19:31:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/3; 8/10] END booster=gblinear, gamma=102.4, learning_rate=0.38083333333333336, max_depth=3, n_estimators=800, reg_alpha=102.4, reg_lambda=0.8; total time=   2.1s\n",
      "[CV 2/3; 8/10] START booster=gblinear, gamma=102.4, learning_rate=0.38083333333333336, max_depth=3, n_estimators=800, reg_alpha=102.4, reg_lambda=0.8\n",
      "[19:31:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/3; 8/10] END booster=gblinear, gamma=102.4, learning_rate=0.38083333333333336, max_depth=3, n_estimators=800, reg_alpha=102.4, reg_lambda=0.8; total time=   2.0s\n",
      "[CV 3/3; 8/10] START booster=gblinear, gamma=102.4, learning_rate=0.38083333333333336, max_depth=3, n_estimators=800, reg_alpha=102.4, reg_lambda=0.8\n",
      "[19:31:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/3; 8/10] END booster=gblinear, gamma=102.4, learning_rate=0.38083333333333336, max_depth=3, n_estimators=800, reg_alpha=102.4, reg_lambda=0.8; total time=   2.0s\n",
      "[CV 1/3; 9/10] START booster=gblinear, gamma=0.4, learning_rate=0.08416666666666667, max_depth=15, n_estimators=400, reg_alpha=3.2, reg_lambda=0.2\n",
      "[19:31:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/3; 9/10] END booster=gblinear, gamma=0.4, learning_rate=0.08416666666666667, max_depth=15, n_estimators=400, reg_alpha=3.2, reg_lambda=0.2; total time=   1.0s\n",
      "[CV 2/3; 9/10] START booster=gblinear, gamma=0.4, learning_rate=0.08416666666666667, max_depth=15, n_estimators=400, reg_alpha=3.2, reg_lambda=0.2\n",
      "[19:31:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 9/10] END booster=gblinear, gamma=0.4, learning_rate=0.08416666666666667, max_depth=15, n_estimators=400, reg_alpha=3.2, reg_lambda=0.2; total time=   0.9s\n",
      "[CV 3/3; 9/10] START booster=gblinear, gamma=0.4, learning_rate=0.08416666666666667, max_depth=15, n_estimators=400, reg_alpha=3.2, reg_lambda=0.2\n",
      "[19:31:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/3; 9/10] END booster=gblinear, gamma=0.4, learning_rate=0.08416666666666667, max_depth=15, n_estimators=400, reg_alpha=3.2, reg_lambda=0.2; total time=   0.9s\n",
      "[CV 1/3; 10/10] START booster=gblinear, gamma=0, learning_rate=0.6775000000000001, max_depth=9, n_estimators=700, reg_alpha=3.2, reg_lambda=0.8\n",
      "[19:31:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/3; 10/10] END booster=gblinear, gamma=0, learning_rate=0.6775000000000001, max_depth=9, n_estimators=700, reg_alpha=3.2, reg_lambda=0.8; total time=   1.7s\n",
      "[CV 2/3; 10/10] START booster=gblinear, gamma=0, learning_rate=0.6775000000000001, max_depth=9, n_estimators=700, reg_alpha=3.2, reg_lambda=0.8\n",
      "[19:31:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/3; 10/10] END booster=gblinear, gamma=0, learning_rate=0.6775000000000001, max_depth=9, n_estimators=700, reg_alpha=3.2, reg_lambda=0.8; total time=   1.7s\n",
      "[CV 3/3; 10/10] START booster=gblinear, gamma=0, learning_rate=0.6775000000000001, max_depth=9, n_estimators=700, reg_alpha=3.2, reg_lambda=0.8\n",
      "[19:31:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"gamma\", \"max_depth\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/3; 10/10] END booster=gblinear, gamma=0, learning_rate=0.6775000000000001, max_depth=9, n_estimators=700, reg_alpha=3.2, reg_lambda=0.8; total time=   1.7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'reg_lambda': 12.8,\n",
       " 'reg_alpha': 0.4,\n",
       " 'n_estimators': 900,\n",
       " 'max_depth': 9,\n",
       " 'learning_rate': 0.01,\n",
       " 'gamma': 0.8,\n",
       " 'booster': 'gbtree'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb_clf= XGBClassifier()\n",
    "\n",
    "\n",
    "#hyperparameters \n",
    "\n",
    "max_depth = [3,6,9,12,15]\n",
    "learning_rate= [float(x) for x in np.linspace(0.01, 0.9, 25)]\n",
    "n_estimators = list(range(100,1000,100))\n",
    "\n",
    "reg_alpha= [0,0.1,0.2,0.4,0.8, 1.6,3.2,6.4,12.8,25.6,51.2,102.4,204.8]\n",
    "reg_lambda= [0,0.1,0.2,0.4,0.8, 1.6,3.2,6.4,12.8,25.6,51.2,102.4,204.8]\n",
    "gamma= [0,0.1,0.2,0.4,0.8, 1.6,3.2,6.4,12.8,25.6,51.2,102.4,204.8]\n",
    "\n",
    "booster=['gbtree', 'gblinear']\n",
    "\n",
    "# Puttin the hyperparameters in a dictionary \n",
    "\n",
    "xgb_hyperparameters= dict(max_depth=max_depth,\n",
    "                          learning_rate=learning_rate,\n",
    "                          n_estimators=n_estimators,\n",
    "                          reg_alpha=reg_alpha,\n",
    "                          reg_lambda=reg_lambda,\n",
    "                          gamma=gamma,\n",
    "                          booster=booster\n",
    "                         )\n",
    "\n",
    "\n",
    "xgb_gridsearch= RandomizedSearchCV(xgb_clf, \n",
    "                                  param_distributions= xgb_hyperparameters,\n",
    "                                  cv=3, verbose=10)\n",
    "\n",
    "xgb_gridsearch.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "xgb_gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f4882b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Confuision Matrix: \n",
      " [[8044  322]\n",
      " [2016  566]]\n",
      "\n",
      " Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87      8366\n",
      "           1       0.64      0.22      0.33      2582\n",
      "\n",
      "    accuracy                           0.79     10948\n",
      "   macro avg       0.72      0.59      0.60     10948\n",
      "weighted avg       0.76      0.79      0.74     10948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Predict the test tesults\n",
    "\n",
    "xgb_y_predict= xgb_gridsearch.predict(X_test)\n",
    "\n",
    "\n",
    "#Model Evaluation ; Confusion Matrix, Classification report, accuracy_score \n",
    "\n",
    "\n",
    "print ('\\n Confuision Matrix: \\n', confusion_matrix(y_test,xgb_y_predict ))\n",
    "print ('\\n Classification Report: \\n', classification_report(y_test,xgb_y_predict ))\n",
    "xgb_accuracy= accuracy_score(y_test, xgb_y_predict)\n",
    "\n",
    "#Append the value of accuracy in the dataframe that we created earlier \n",
    "\n",
    "result.loc[4]= ['XGBoost Classifier', xgb_accuracy]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8fd94402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN classifier</td>\n",
       "      <td>0.716204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree classifier</td>\n",
       "      <td>0.758221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest classifier</td>\n",
       "      <td>0.755663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.235842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>0.786445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  Accuracy Score\n",
       "0            KNN classifier        0.716204\n",
       "1  Decision Tree classifier        0.758221\n",
       "2   RandomForest classifier        0.755663\n",
       "3       Logistic Regression        0.235842\n",
       "4        XGBoost Classifier        0.786445"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a082d04",
   "metadata": {},
   "source": [
    "# Final Observation : XGBoost gives the highest accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d864e877",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
